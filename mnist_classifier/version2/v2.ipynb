{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2523e1b",
   "metadata": {},
   "source": [
    "# 2nd attempt at MNIST classifier\n",
    "This code implements a simple neural network of 2 hidden layers of 16 units each with ReLU activation, and 1 output layer of 10 units with softmax activation, implemented from scratch using numpy. It also makes use of regularization, mini-batch gradient descent for more optimization\n",
    "\n",
    "the data is taking from [kaggle](https://www.kaggle.com/competitions/digit-recognizer/data), which contains all images flattened and present in a csv file. As convolution is not involved, this is ok for current purpose. \n",
    "\n",
    "\n",
    "### Results\n",
    "after applying just regularization, with lamdba = 0.001, the accuracy drop to about 92%, with 0.01, it is about 90%, and same with 0.1. \n",
    "\n",
    "With mini-batch gradient descent, batch_size=64 and lambda=0.05, alpha=0.1, with at just epoch=4, it reached an accuracy of 92.4%, which took version1 2350 iterations using batch gradient descent, proving mini-batch gradient descent to be highly efficient. after about 210 epochs, it is converged to ~98% accuracy. Although its accuracy on cross validation was 95.4%, much lower than training set accuracy, but still more than version1 which didn't use regularization (v1 had CV accuracy = 94.1%)\n",
    "\n",
    "-------------------\n",
    "### Github Instruction\n",
    "after downloading the files in parent directory, `/kaggle/mnist_classifier/version2`, extract `dataset.zip` into folder `dataset`. If you want to load in pretrained weights, use `weights_v2.1.json`. it contains a dict, with keys (W1, b1, ...) mapped with their matrices. Load them in and convert to np.array and you should be good to go (Although I haven't tested it, _yet_). It also contains a 'details' key with the hypterparameters during training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e29237-a4fa-4d5a-96cf-f0db600ccfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6b4cbd",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "the dataset directory contains the data downloaded directly as is from kaggle, without any modifications. So after loading it, we have to split it, scale the gray scale values b/w 0 to 1, and convert from pandas DF to numpy.NDarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af55c28-147e-4416-aea1-b7ac396519c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 9, 1, ..., 2, 6, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./dataset/train.csv')\n",
    "train_data = np.array(train_data)\n",
    "test_data = pd.read_csv('./dataset/test.csv')\n",
    "test_data = np.array(test_data)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "np.random.shuffle(train_data)\n",
    "\n",
    "#separate data into training and cross validation set, and transpose so that data is column-wise, not row-wise\n",
    "cv = train_data[:3000].T\n",
    "train = train_data[3000:].T\n",
    "\n",
    "\n",
    "X_train = train[1:]\n",
    "X_train = X_train / 255 \n",
    "Y_train = train[0].reshape((1, -1))\n",
    "m = X_train.shape[1]\n",
    "\n",
    "X_cv = cv[1:]\n",
    "X_cv = X_cv / 255\n",
    "Y_cv = cv[0].reshape((1, -1))\n",
    "\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1732a1-090f-4055-8bab-97039c0d4d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e027e12a-b2dd-46c3-af88-febf9538c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x-np.max(x, axis=0, keepdims=True))\n",
    "    \n",
    "    return exp_x/np.sum(exp_x, axis=0, keepdims=True)\n",
    "    \n",
    "def sparse_categorical_cross_entropy_loss(predictions, y):\n",
    "    return -np.sum(y * np.log(predictions)) / y.size\n",
    "\n",
    "\n",
    "def get_prediction(A3):\n",
    "    return np.argmax(A3, axis=0, keepdims=True)\n",
    "\n",
    "def accuracy(prediction, Y):\n",
    "    return np.sum(prediction==Y)/Y.size\n",
    "\n",
    "def one_hot_encode(Y):\n",
    "    encoded_Y = np.zeros((10, Y.size))\n",
    "\n",
    "    encoded_Y[Y, np.arange(Y.size)] = 1\n",
    "    return encoded_Y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be76c11-81fd-4de5-a0df-c65b9d470e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "054d5b93-42ea-4789-bc92-ace84879ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights():\n",
    "    #random_sample returns a uniform distribution from 0 to 1, in atleast v2.2\n",
    "\n",
    "    W1 = np.random.random_sample((16, 784)) - 0.5\n",
    "    b1 = np.random.random_sample((16, 1)) - 0.5\n",
    "\n",
    "    W2 = np.random.random_sample((16, 16))- 0.5\n",
    "    b2 = np.random.random_sample((16, 1))- 0.5\n",
    "\n",
    "    W3 = np.random.random_sample((10, 16))- 0.5\n",
    "    b3 = np.random.random_sample((10, 1))- 0.5\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, W3, b3, X):\n",
    "\n",
    "    Z1 = np.matmul(W1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "\n",
    "    Z2 = np.matmul(W2, A1) + b2\n",
    "    A2 = relu(Z2)\n",
    "\n",
    "    Z3 = np.matmul(W3, A2) + b3\n",
    "    A3 = softmax(Z3)\n",
    "\n",
    "    return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "def back_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, X, y, lambda_):\n",
    "    \"\"\"\n",
    "    Assuming y has shape (10, m)\n",
    "    \"\"\"\n",
    "    m = y.shape[1]\n",
    "\n",
    "    ## layer 3\n",
    "    # dA3 = -y / A3\n",
    "    dZ3 = A3 - y\n",
    "\n",
    "    dW3 = np.matmul(dZ3, A2.T) / m + lambda_ / m * W3\n",
    "    db3 = np.sum(dZ3, axis=1, keepdims=True) / m\n",
    "\n",
    "    ## layer 2\n",
    "    dA2 = np.matmul(W3.T, dZ3) \n",
    "    dZ2 = dA2 * (Z2 > 0)\n",
    "\n",
    "    dW2 = np.matmul(dZ2, A1.T) / m + lambda_ / m * W2\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "\n",
    "    ## layer 1\n",
    "    dA1 = np.matmul(W2.T, dZ2)\n",
    "    dZ1 = dA1 * (Z1 > 0)\n",
    "\n",
    "    dW1 = np.matmul(dZ1, X.T) / m + lambda_/m * W1\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "\n",
    "    return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "def update_params(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha):\n",
    "\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * db1\n",
    "\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "\n",
    "    W3 -= alpha * dW3\n",
    "    b3 -= alpha * db3\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "def gradient_descent(X, Y, epoch, alpha, lambda_=0.01, batch_size=64, W1=None, b1=None, W2=None, b2=None, W3=None, b3=None):\n",
    "\n",
    "    n, m = X.shape\n",
    "    y_copy = one_hot_encode(Y)\n",
    "    print(y_copy.shape)\n",
    "    x_copy = X.copy()\n",
    "    \n",
    "    if W1 is None:\n",
    "        W1, b1, W2, b2, W3, b3 = initialize_weights()\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(epoch):\n",
    "\n",
    "        #this tracks the number of correct predictions done by the algorithm\n",
    "        y_correct = 0\n",
    "\n",
    "        for j in range(0, m, batch_size):\n",
    "            x_batch = x_copy[:, j: j+batch_size]\n",
    "            y_batch = y_copy[:, j: j+batch_size]\n",
    "            \n",
    "            Z1, A1, Z2, A2, Z3, A3 = forward_prop(W1, b1, W2, b2, W3, b3, x_batch)            \n",
    "            dW1, db1, dW2, db2, dW3, db3 = back_prop(Z1, A1, Z2, A2, Z3, A3, W1, W2, W3, x_batch, y_batch, lambda_)    \n",
    "            W1, b1, W2, b2, W3, b3 = update_params(W1, b1, W2, b2, W3, b3, dW1, db1, dW2, db2, dW3, db3, alpha)\n",
    "            \n",
    "            \n",
    "            prediction = get_prediction(A3)\n",
    "            \n",
    "            y_correct += np.sum(prediction == np.argmax(y_batch, axis=0, keepdims=True)) \n",
    "            \n",
    "        print(f\"Iteration: {i}, took {time.time()-start}s- Accuracy={y_correct/m}\")\n",
    "        start = time.time()\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "        \n",
    "def make_prediction(W1, b1, W2, b2, W3, b3, X):\n",
    "    _, _, _, _, _, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "    predictions = get_prediction(A3)\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64892cb7-47a5-446c-9b76-53e779b861c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8908f6e5-a836-4093-9be8-14301a23c357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 39000)\n",
      "Iteration: 0, took 0.47753167152404785s- Accuracy=0.7311794871794872\n",
      "Iteration: 1, took 0.5024430751800537s- Accuracy=0.8822051282051282\n",
      "Iteration: 2, took 0.4727592468261719s- Accuracy=0.9052307692307693\n",
      "Iteration: 3, took 0.4579184055328369s- Accuracy=0.9166153846153846\n",
      "Iteration: 4, took 0.5449190139770508s- Accuracy=0.924923076923077\n",
      "Iteration: 5, took 0.5584194660186768s- Accuracy=0.9308205128205128\n",
      "Iteration: 6, took 0.5713837146759033s- Accuracy=0.9368717948717948\n",
      "Iteration: 7, took 0.53670334815979s- Accuracy=0.940923076923077\n",
      "Iteration: 8, took 0.49346113204956055s- Accuracy=0.9443076923076923\n",
      "Iteration: 9, took 0.47324705123901367s- Accuracy=0.9471538461538461\n",
      "Iteration: 10, took 0.5330188274383545s- Accuracy=0.949974358974359\n",
      "Iteration: 11, took 0.5202507972717285s- Accuracy=0.9516666666666667\n",
      "Iteration: 12, took 0.47409749031066895s- Accuracy=0.9538974358974359\n",
      "Iteration: 13, took 0.49549150466918945s- Accuracy=0.9558461538461539\n",
      "Iteration: 14, took 0.4687535762786865s- Accuracy=0.9575641025641025\n",
      "Iteration: 15, took 0.5227329730987549s- Accuracy=0.9587948717948718\n",
      "Iteration: 16, took 0.5062599182128906s- Accuracy=0.9605128205128205\n",
      "Iteration: 17, took 0.5977303981781006s- Accuracy=0.9612051282051282\n",
      "Iteration: 18, took 0.5937013626098633s- Accuracy=0.9625128205128205\n",
      "Iteration: 19, took 0.46801185607910156s- Accuracy=0.9628205128205128\n",
      "Iteration: 20, took 0.5568575859069824s- Accuracy=0.9637692307692308\n",
      "Iteration: 21, took 0.4708268642425537s- Accuracy=0.9643589743589743\n",
      "Iteration: 22, took 0.6124792098999023s- Accuracy=0.9648205128205128\n",
      "Iteration: 23, took 0.46459221839904785s- Accuracy=0.9652564102564103\n",
      "Iteration: 24, took 0.5665900707244873s- Accuracy=0.9654358974358974\n",
      "Iteration: 25, took 0.47740840911865234s- Accuracy=0.9660512820512821\n",
      "Iteration: 26, took 0.474773645401001s- Accuracy=0.9666153846153847\n",
      "Iteration: 27, took 0.4680616855621338s- Accuracy=0.9670769230769231\n",
      "Iteration: 28, took 0.5333755016326904s- Accuracy=0.9671025641025641\n",
      "Iteration: 29, took 0.46389031410217285s- Accuracy=0.9677692307692307\n",
      "Iteration: 30, took 0.5342731475830078s- Accuracy=0.968025641025641\n",
      "Iteration: 31, took 0.5080130100250244s- Accuracy=0.9684102564102565\n",
      "Iteration: 32, took 0.5304710865020752s- Accuracy=0.9684871794871794\n",
      "Iteration: 33, took 0.47852659225463867s- Accuracy=0.968974358974359\n",
      "Iteration: 34, took 0.501849889755249s- Accuracy=0.9691025641025641\n",
      "Iteration: 35, took 0.479644775390625s- Accuracy=0.9696153846153847\n",
      "Iteration: 36, took 0.5423290729522705s- Accuracy=0.9695641025641025\n",
      "Iteration: 37, took 0.47870659828186035s- Accuracy=0.9696666666666667\n",
      "Iteration: 38, took 0.5004491806030273s- Accuracy=0.9696410256410256\n",
      "Iteration: 39, took 0.4399428367614746s- Accuracy=0.9700769230769231\n",
      "Iteration: 40, took 0.483959436416626s- Accuracy=0.97\n",
      "Iteration: 41, took 0.536618709564209s- Accuracy=0.9703589743589743\n",
      "Iteration: 42, took 0.5250928401947021s- Accuracy=0.9707692307692307\n",
      "Iteration: 43, took 0.4795856475830078s- Accuracy=0.9710512820512821\n",
      "Iteration: 44, took 0.5201208591461182s- Accuracy=0.9708974358974359\n",
      "Iteration: 45, took 0.4418342113494873s- Accuracy=0.9715897435897436\n",
      "Iteration: 46, took 0.49480319023132324s- Accuracy=0.9718205128205128\n",
      "Iteration: 47, took 0.46498775482177734s- Accuracy=0.9722564102564103\n",
      "Iteration: 48, took 0.4556467533111572s- Accuracy=0.972025641025641\n",
      "Iteration: 49, took 0.5236833095550537s- Accuracy=0.9722307692307692\n",
      "Iteration: 50, took 0.4488515853881836s- Accuracy=0.9724871794871794\n",
      "Iteration: 51, took 0.5307838916778564s- Accuracy=0.972948717948718\n",
      "Iteration: 52, took 0.45761561393737793s- Accuracy=0.9726923076923077\n",
      "Iteration: 53, took 0.5207760334014893s- Accuracy=0.9730769230769231\n",
      "Iteration: 54, took 0.49173426628112793s- Accuracy=0.9732051282051282\n",
      "Iteration: 55, took 0.49732136726379395s- Accuracy=0.9734615384615385\n",
      "Iteration: 56, took 0.5324900150299072s- Accuracy=0.9735897435897436\n",
      "Iteration: 57, took 0.5637106895446777s- Accuracy=0.9737948717948718\n",
      "Iteration: 58, took 0.5043020248413086s- Accuracy=0.9742820512820513\n",
      "Iteration: 59, took 0.46148109436035156s- Accuracy=0.973948717948718\n",
      "Iteration: 60, took 0.4470827579498291s- Accuracy=0.974025641025641\n",
      "Iteration: 61, took 0.5125868320465088s- Accuracy=0.9744102564102564\n",
      "Iteration: 62, took 0.46781229972839355s- Accuracy=0.9744615384615385\n",
      "Iteration: 63, took 0.5938329696655273s- Accuracy=0.9747948717948718\n",
      "Iteration: 64, took 0.6341767311096191s- Accuracy=0.974948717948718\n",
      "Iteration: 65, took 0.5066094398498535s- Accuracy=0.9747179487179487\n",
      "Iteration: 66, took 0.4693624973297119s- Accuracy=0.9747435897435898\n",
      "Iteration: 67, took 0.46703076362609863s- Accuracy=0.975025641025641\n",
      "Iteration: 68, took 0.43796658515930176s- Accuracy=0.975025641025641\n",
      "Iteration: 69, took 0.5561676025390625s- Accuracy=0.9753076923076923\n",
      "Iteration: 70, took 0.538546085357666s- Accuracy=0.9752564102564103\n",
      "Iteration: 71, took 0.547020435333252s- Accuracy=0.9758205128205129\n",
      "Iteration: 72, took 0.4837992191314697s- Accuracy=0.9757692307692307\n",
      "Iteration: 73, took 0.5345184803009033s- Accuracy=0.9756666666666667\n",
      "Iteration: 74, took 0.4782571792602539s- Accuracy=0.975948717948718\n",
      "Iteration: 75, took 0.46975064277648926s- Accuracy=0.9757948717948718\n",
      "Iteration: 76, took 0.48883843421936035s- Accuracy=0.9764102564102564\n",
      "Iteration: 77, took 0.5183210372924805s- Accuracy=0.975948717948718\n",
      "Iteration: 78, took 0.47672200202941895s- Accuracy=0.9761538461538461\n",
      "Iteration: 79, took 0.5728886127471924s- Accuracy=0.975974358974359\n",
      "Iteration: 80, took 0.5581085681915283s- Accuracy=0.9762820512820513\n",
      "Iteration: 81, took 0.5785629749298096s- Accuracy=0.9764102564102564\n",
      "Iteration: 82, took 0.5304155349731445s- Accuracy=0.9761538461538461\n",
      "Iteration: 83, took 0.48894214630126953s- Accuracy=0.9763846153846154\n",
      "Iteration: 84, took 0.49483656883239746s- Accuracy=0.9767692307692307\n",
      "Iteration: 85, took 0.5184340476989746s- Accuracy=0.9766666666666667\n",
      "Iteration: 86, took 0.5194382667541504s- Accuracy=0.9765641025641025\n",
      "Iteration: 87, took 0.4983713626861572s- Accuracy=0.9768974358974359\n",
      "Iteration: 88, took 0.5235435962677002s- Accuracy=0.9768461538461538\n",
      "Iteration: 89, took 0.4889109134674072s- Accuracy=0.977051282051282\n",
      "Iteration: 90, took 0.5152237415313721s- Accuracy=0.9766666666666667\n",
      "Iteration: 91, took 0.4645087718963623s- Accuracy=0.9765897435897436\n",
      "Iteration: 92, took 0.4788944721221924s- Accuracy=0.9768974358974359\n",
      "Iteration: 93, took 0.4835011959075928s- Accuracy=0.9765641025641025\n",
      "Iteration: 94, took 0.46278858184814453s- Accuracy=0.9771282051282051\n",
      "Iteration: 95, took 0.4916667938232422s- Accuracy=0.9772564102564103\n",
      "Iteration: 96, took 0.5025699138641357s- Accuracy=0.9772820512820513\n",
      "Iteration: 97, took 0.4766983985900879s- Accuracy=0.9771794871794872\n",
      "Iteration: 98, took 0.481921911239624s- Accuracy=0.9773333333333334\n",
      "Iteration: 99, took 0.457139253616333s- Accuracy=0.9772564102564103\n",
      "Iteration: 100, took 0.5045108795166016s- Accuracy=0.9773846153846154\n",
      "Iteration: 101, took 0.462172269821167s- Accuracy=0.9772820512820513\n",
      "Iteration: 102, took 0.46912503242492676s- Accuracy=0.9774615384615385\n",
      "Iteration: 103, took 0.45640063285827637s- Accuracy=0.9775897435897436\n",
      "Iteration: 104, took 0.4772200584411621s- Accuracy=0.9775128205128205\n",
      "Iteration: 105, took 0.5413575172424316s- Accuracy=0.9778205128205129\n",
      "Iteration: 106, took 0.4788477420806885s- Accuracy=0.978\n",
      "Iteration: 107, took 0.6070389747619629s- Accuracy=0.9776666666666667\n",
      "Iteration: 108, took 0.5603742599487305s- Accuracy=0.977948717948718\n",
      "Iteration: 109, took 0.4616563320159912s- Accuracy=0.9776923076923076\n",
      "Iteration: 110, took 0.4723625183105469s- Accuracy=0.9780769230769231\n",
      "Iteration: 111, took 0.4499373435974121s- Accuracy=0.9783333333333334\n",
      "Iteration: 112, took 0.5119922161102295s- Accuracy=0.9781538461538462\n",
      "Iteration: 113, took 0.49700236320495605s- Accuracy=0.9781794871794872\n",
      "Iteration: 114, took 0.43179941177368164s- Accuracy=0.9784615384615385\n",
      "Iteration: 115, took 0.4784975051879883s- Accuracy=0.9779230769230769\n",
      "Iteration: 116, took 0.4978342056274414s- Accuracy=0.9784358974358974\n",
      "Iteration: 117, took 0.4678659439086914s- Accuracy=0.9782051282051282\n",
      "Iteration: 118, took 0.4376490116119385s- Accuracy=0.9781538461538462\n",
      "Iteration: 119, took 0.44933319091796875s- Accuracy=0.9783589743589743\n",
      "Iteration: 120, took 0.4707348346710205s- Accuracy=0.9782564102564103\n",
      "Iteration: 121, took 0.4903435707092285s- Accuracy=0.9782564102564103\n",
      "Iteration: 122, took 0.440244197845459s- Accuracy=0.9784358974358974\n",
      "Iteration: 123, took 0.4845559597015381s- Accuracy=0.9784615384615385\n",
      "Iteration: 124, took 0.48493480682373047s- Accuracy=0.9783333333333334\n",
      "Iteration: 125, took 0.5446782112121582s- Accuracy=0.9783846153846154\n",
      "Iteration: 126, took 0.5101656913757324s- Accuracy=0.9786153846153847\n",
      "Iteration: 127, took 0.5091526508331299s- Accuracy=0.9784102564102564\n",
      "Iteration: 128, took 0.554081916809082s- Accuracy=0.9785384615384616\n",
      "Iteration: 129, took 0.46071791648864746s- Accuracy=0.9782820512820513\n",
      "Iteration: 130, took 0.5053653717041016s- Accuracy=0.9783846153846154\n",
      "Iteration: 131, took 0.4775071144104004s- Accuracy=0.978948717948718\n",
      "Iteration: 132, took 0.521298885345459s- Accuracy=0.9787692307692307\n",
      "Iteration: 133, took 0.5021781921386719s- Accuracy=0.9784358974358974\n",
      "Iteration: 134, took 0.4555075168609619s- Accuracy=0.979025641025641\n",
      "Iteration: 135, took 0.4505188465118408s- Accuracy=0.9791282051282051\n",
      "Iteration: 136, took 0.5044357776641846s- Accuracy=0.9789230769230769\n",
      "Iteration: 137, took 0.5644474029541016s- Accuracy=0.9787435897435898\n",
      "Iteration: 138, took 0.49195337295532227s- Accuracy=0.9788205128205129\n",
      "Iteration: 139, took 0.46532487869262695s- Accuracy=0.9789230769230769\n",
      "Iteration: 140, took 0.4809603691101074s- Accuracy=0.9786666666666667\n",
      "Iteration: 141, took 0.4775998592376709s- Accuracy=0.979\n",
      "Iteration: 142, took 0.4897797107696533s- Accuracy=0.9788717948717949\n",
      "Iteration: 143, took 0.5418574810028076s- Accuracy=0.9791794871794872\n",
      "Iteration: 144, took 0.4930551052093506s- Accuracy=0.979051282051282\n",
      "Iteration: 145, took 0.5109405517578125s- Accuracy=0.9792307692307692\n",
      "Iteration: 146, took 0.47582101821899414s- Accuracy=0.9792564102564103\n",
      "Iteration: 147, took 0.4922008514404297s- Accuracy=0.9788974358974359\n",
      "Iteration: 148, took 0.4952423572540283s- Accuracy=0.9791282051282051\n",
      "Iteration: 149, took 0.4729492664337158s- Accuracy=0.9791025641025641\n",
      "Iteration: 150, took 0.517423152923584s- Accuracy=0.979025641025641\n",
      "Iteration: 151, took 0.6616930961608887s- Accuracy=0.9787179487179487\n",
      "Iteration: 152, took 0.5540058612823486s- Accuracy=0.978948717948718\n",
      "Iteration: 153, took 0.5447463989257812s- Accuracy=0.9791538461538462\n",
      "Iteration: 154, took 0.5781128406524658s- Accuracy=0.9792564102564103\n",
      "Iteration: 155, took 0.603508710861206s- Accuracy=0.9789230769230769\n",
      "Iteration: 156, took 0.5236282348632812s- Accuracy=0.9787179487179487\n",
      "Iteration: 157, took 0.43772196769714355s- Accuracy=0.979051282051282\n",
      "Iteration: 158, took 0.5778529644012451s- Accuracy=0.9793846153846154\n",
      "Iteration: 159, took 0.4962637424468994s- Accuracy=0.978948717948718\n",
      "Iteration: 160, took 0.514796257019043s- Accuracy=0.9791282051282051\n",
      "Iteration: 161, took 0.5259685516357422s- Accuracy=0.9792564102564103\n",
      "Iteration: 162, took 0.48685383796691895s- Accuracy=0.9793846153846154\n",
      "Iteration: 163, took 0.46135997772216797s- Accuracy=0.9792051282051282\n",
      "Iteration: 164, took 0.5276682376861572s- Accuracy=0.9795384615384616\n",
      "Iteration: 165, took 0.5346081256866455s- Accuracy=0.9796923076923076\n",
      "Iteration: 166, took 0.5046069622039795s- Accuracy=0.9793846153846154\n",
      "Iteration: 167, took 0.4741199016571045s- Accuracy=0.9794102564102564\n",
      "Iteration: 168, took 0.5016233921051025s- Accuracy=0.9794871794871794\n",
      "Iteration: 169, took 0.4677150249481201s- Accuracy=0.9793589743589743\n",
      "Iteration: 170, took 0.5500822067260742s- Accuracy=0.9795897435897436\n",
      "Iteration: 171, took 0.4836275577545166s- Accuracy=0.9795384615384616\n",
      "Iteration: 172, took 0.5958318710327148s- Accuracy=0.9797435897435898\n",
      "Iteration: 173, took 0.45817995071411133s- Accuracy=0.979974358974359\n",
      "Iteration: 174, took 0.48845982551574707s- Accuracy=0.9795897435897436\n",
      "Iteration: 175, took 0.4694700241088867s- Accuracy=0.98\n",
      "Iteration: 176, took 0.48070788383483887s- Accuracy=0.9796410256410256\n",
      "Iteration: 177, took 0.47367167472839355s- Accuracy=0.9795128205128205\n",
      "Iteration: 178, took 0.5003433227539062s- Accuracy=0.9797692307692307\n",
      "Iteration: 179, took 0.4338068962097168s- Accuracy=0.9797948717948718\n",
      "Iteration: 180, took 0.49678587913513184s- Accuracy=0.9796410256410256\n",
      "Iteration: 181, took 0.4641726016998291s- Accuracy=0.9797692307692307\n",
      "Iteration: 182, took 0.4629628658294678s- Accuracy=0.9796153846153847\n",
      "Iteration: 183, took 0.49607419967651367s- Accuracy=0.9795128205128205\n",
      "Iteration: 184, took 0.5536341667175293s- Accuracy=0.9794615384615385\n",
      "Iteration: 185, took 0.4763526916503906s- Accuracy=0.9797692307692307\n",
      "Iteration: 186, took 0.48677802085876465s- Accuracy=0.9795641025641025\n",
      "Iteration: 187, took 0.4603538513183594s- Accuracy=0.9796923076923076\n",
      "Iteration: 188, took 0.4934988021850586s- Accuracy=0.9795384615384616\n",
      "Iteration: 189, took 0.47617411613464355s- Accuracy=0.9795384615384616\n",
      "Iteration: 190, took 0.45605921745300293s- Accuracy=0.9797692307692307\n",
      "Iteration: 191, took 0.5770597457885742s- Accuracy=0.9798205128205129\n",
      "Iteration: 192, took 0.5600745677947998s- Accuracy=0.9798205128205129\n",
      "Iteration: 193, took 0.49052858352661133s- Accuracy=0.9796153846153847\n",
      "Iteration: 194, took 0.5107121467590332s- Accuracy=0.979974358974359\n",
      "Iteration: 195, took 0.45678043365478516s- Accuracy=0.979948717948718\n",
      "Iteration: 196, took 0.5485174655914307s- Accuracy=0.98\n",
      "Iteration: 197, took 0.5504846572875977s- Accuracy=0.9798205128205129\n",
      "Iteration: 198, took 0.4679982662200928s- Accuracy=0.9795641025641025\n",
      "Iteration: 199, took 0.5023691654205322s- Accuracy=0.9801794871794872\n",
      "Iteration: 200, took 0.4772028923034668s- Accuracy=0.9798461538461538\n",
      "Iteration: 201, took 0.5712528228759766s- Accuracy=0.9797692307692307\n",
      "Iteration: 202, took 0.5986497402191162s- Accuracy=0.9798717948717949\n",
      "Iteration: 203, took 0.51190185546875s- Accuracy=0.9798205128205129\n",
      "Iteration: 204, took 0.5277249813079834s- Accuracy=0.9796410256410256\n",
      "Iteration: 205, took 0.4820899963378906s- Accuracy=0.9803333333333333\n",
      "Iteration: 206, took 0.5926868915557861s- Accuracy=0.9802307692307692\n",
      "Iteration: 207, took 0.4498612880706787s- Accuracy=0.9803333333333333\n",
      "Iteration: 208, took 0.5834391117095947s- Accuracy=0.980051282051282\n",
      "Iteration: 209, took 0.5176513195037842s- Accuracy=0.9801794871794872\n",
      "Iteration: 210, took 0.5774791240692139s- Accuracy=0.9797692307692307\n",
      "Iteration: 211, took 0.5459766387939453s- Accuracy=0.9797435897435898\n",
      "Iteration: 212, took 0.520714282989502s- Accuracy=0.9803589743589743\n",
      "Iteration: 213, took 0.457794189453125s- Accuracy=0.9798461538461538\n",
      "Iteration: 214, took 0.5416295528411865s- Accuracy=0.980025641025641\n",
      "Iteration: 215, took 0.47403812408447266s- Accuracy=0.9802051282051282\n",
      "Iteration: 216, took 0.5912141799926758s- Accuracy=0.98\n",
      "Iteration: 217, took 0.47672057151794434s- Accuracy=0.9802564102564103\n",
      "Iteration: 218, took 0.4750089645385742s- Accuracy=0.9803076923076923\n",
      "Iteration: 219, took 0.5042028427124023s- Accuracy=0.9802564102564103\n",
      "Iteration: 220, took 0.49416589736938477s- Accuracy=0.9805384615384616\n",
      "Iteration: 221, took 0.475663423538208s- Accuracy=0.9803589743589743\n",
      "Iteration: 222, took 0.47161436080932617s- Accuracy=0.9802820512820513\n",
      "Iteration: 223, took 0.5446105003356934s- Accuracy=0.9802820512820513\n",
      "Iteration: 224, took 0.49176836013793945s- Accuracy=0.9801025641025641\n",
      "Iteration: 225, took 0.4814910888671875s- Accuracy=0.979948717948718\n",
      "Iteration: 226, took 0.48491859436035156s- Accuracy=0.9797692307692307\n",
      "Iteration: 227, took 0.5325338840484619s- Accuracy=0.979948717948718\n",
      "Iteration: 228, took 0.48055481910705566s- Accuracy=0.9802307692307692\n",
      "Iteration: 229, took 0.510561466217041s- Accuracy=0.9801794871794872\n",
      "Iteration: 230, took 0.49283576011657715s- Accuracy=0.9803076923076923\n",
      "Iteration: 231, took 0.5660533905029297s- Accuracy=0.9798717948717949\n",
      "Iteration: 232, took 0.6149685382843018s- Accuracy=0.9799230769230769\n",
      "Iteration: 233, took 0.45171689987182617s- Accuracy=0.9802051282051282\n",
      "Iteration: 234, took 0.5120875835418701s- Accuracy=0.9802564102564103\n",
      "Iteration: 235, took 0.4635131359100342s- Accuracy=0.9802820512820513\n",
      "Iteration: 236, took 0.49593544006347656s- Accuracy=0.9802051282051282\n",
      "Iteration: 237, took 0.48978281021118164s- Accuracy=0.980051282051282\n",
      "Iteration: 238, took 0.4903690814971924s- Accuracy=0.9802820512820513\n",
      "Iteration: 239, took 0.5018713474273682s- Accuracy=0.9801025641025641\n",
      "Iteration: 240, took 0.5116193294525146s- Accuracy=0.9803076923076923\n",
      "Iteration: 241, took 0.5038018226623535s- Accuracy=0.980025641025641\n",
      "Iteration: 242, took 0.4596107006072998s- Accuracy=0.979948717948718\n",
      "Iteration: 243, took 0.5250518321990967s- Accuracy=0.9804102564102564\n",
      "Iteration: 244, took 0.5445230007171631s- Accuracy=0.9802820512820513\n",
      "Iteration: 245, took 0.5077667236328125s- Accuracy=0.9798717948717949\n",
      "Iteration: 246, took 0.5177342891693115s- Accuracy=0.9801794871794872\n",
      "Iteration: 247, took 0.5093274116516113s- Accuracy=0.9801538461538462\n",
      "Iteration: 248, took 0.6473047733306885s- Accuracy=0.980025641025641\n",
      "Iteration: 249, took 0.5920374393463135s- Accuracy=0.980025641025641\n",
      "Iteration: 250, took 0.5778110027313232s- Accuracy=0.9803076923076923\n",
      "Iteration: 251, took 0.5311672687530518s- Accuracy=0.9801282051282051\n",
      "Iteration: 252, took 0.5304765701293945s- Accuracy=0.9802820512820513\n",
      "Iteration: 253, took 0.5856888294219971s- Accuracy=0.9801538461538462\n",
      "Iteration: 254, took 0.5548579692840576s- Accuracy=0.9804102564102564\n",
      "Iteration: 255, took 0.5566694736480713s- Accuracy=0.9802820512820513\n",
      "Iteration: 256, took 0.5321712493896484s- Accuracy=0.9802051282051282\n",
      "Iteration: 257, took 0.46129870414733887s- Accuracy=0.979948717948718\n",
      "Iteration: 258, took 0.4875674247741699s- Accuracy=0.9808205128205129\n",
      "Iteration: 259, took 0.5343372821807861s- Accuracy=0.9803589743589743\n",
      "Iteration: 260, took 0.4859762191772461s- Accuracy=0.9803076923076923\n",
      "Iteration: 261, took 0.5185284614562988s- Accuracy=0.9804358974358974\n",
      "Iteration: 262, took 0.5248172283172607s- Accuracy=0.9805384615384616\n",
      "Iteration: 263, took 0.5235953330993652s- Accuracy=0.9806410256410256\n",
      "Iteration: 264, took 0.5206270217895508s- Accuracy=0.9805641025641025\n",
      "Iteration: 265, took 0.4667801856994629s- Accuracy=0.9800769230769231\n",
      "Iteration: 266, took 0.5136508941650391s- Accuracy=0.980051282051282\n",
      "Iteration: 267, took 0.4550447463989258s- Accuracy=0.9804358974358974\n",
      "Iteration: 268, took 0.5328452587127686s- Accuracy=0.9804358974358974\n",
      "Iteration: 269, took 0.49973368644714355s- Accuracy=0.9801538461538462\n",
      "Iteration: 270, took 0.4703381061553955s- Accuracy=0.9805897435897436\n",
      "Iteration: 271, took 0.5419223308563232s- Accuracy=0.9804102564102564\n",
      "Iteration: 272, took 0.5334389209747314s- Accuracy=0.9802564102564103\n",
      "Iteration: 273, took 0.4488205909729004s- Accuracy=0.98\n",
      "Iteration: 274, took 0.5086178779602051s- Accuracy=0.9801794871794872\n",
      "Iteration: 275, took 0.5147848129272461s- Accuracy=0.98\n",
      "Iteration: 276, took 0.48897838592529297s- Accuracy=0.9802051282051282\n",
      "Iteration: 277, took 0.5110199451446533s- Accuracy=0.9801282051282051\n",
      "Iteration: 278, took 0.5965640544891357s- Accuracy=0.979948717948718\n",
      "Iteration: 279, took 0.5513484477996826s- Accuracy=0.9803589743589743\n",
      "Iteration: 280, took 0.48686838150024414s- Accuracy=0.9803333333333333\n",
      "Iteration: 281, took 0.48459959030151367s- Accuracy=0.9804615384615385\n",
      "Iteration: 282, took 0.4713146686553955s- Accuracy=0.9805641025641025\n",
      "Iteration: 283, took 0.49038028717041016s- Accuracy=0.9801282051282051\n",
      "Iteration: 284, took 0.5333716869354248s- Accuracy=0.98\n",
      "Iteration: 285, took 0.5738942623138428s- Accuracy=0.9804102564102564\n",
      "Iteration: 286, took 0.656247615814209s- Accuracy=0.9806153846153847\n",
      "Iteration: 287, took 0.577425479888916s- Accuracy=0.98\n",
      "Iteration: 288, took 0.7380335330963135s- Accuracy=0.9801794871794872\n",
      "Iteration: 289, took 0.8279232978820801s- Accuracy=0.9804102564102564\n",
      "Iteration: 290, took 0.5411489009857178s- Accuracy=0.9800769230769231\n",
      "Iteration: 291, took 0.5426516532897949s- Accuracy=0.9803589743589743\n",
      "Iteration: 292, took 0.5229964256286621s- Accuracy=0.9803076923076923\n",
      "Iteration: 293, took 0.4879782199859619s- Accuracy=0.9802564102564103\n",
      "Iteration: 294, took 0.5823237895965576s- Accuracy=0.9799230769230769\n",
      "Iteration: 295, took 0.5735323429107666s- Accuracy=0.9803589743589743\n",
      "Iteration: 296, took 0.5167028903961182s- Accuracy=0.9803076923076923\n",
      "Iteration: 297, took 0.5452084541320801s- Accuracy=0.9805641025641025\n",
      "Iteration: 298, took 0.48291563987731934s- Accuracy=0.9803846153846154\n",
      "Iteration: 299, took 0.5218663215637207s- Accuracy=0.9802564102564103\n",
      "Iteration: 300, took 0.5275206565856934s- Accuracy=0.9805384615384616\n",
      "Iteration: 301, took 0.4900672435760498s- Accuracy=0.9804358974358974\n",
      "Iteration: 302, took 0.525709867477417s- Accuracy=0.9804615384615385\n",
      "Iteration: 303, took 0.4866800308227539s- Accuracy=0.9803846153846154\n",
      "Iteration: 304, took 0.5037741661071777s- Accuracy=0.98\n",
      "Iteration: 305, took 0.46686577796936035s- Accuracy=0.980025641025641\n",
      "Iteration: 306, took 0.4890270233154297s- Accuracy=0.9801025641025641\n",
      "Iteration: 307, took 0.48560523986816406s- Accuracy=0.9804871794871794\n",
      "Iteration: 308, took 0.4637753963470459s- Accuracy=0.9804102564102564\n",
      "Iteration: 309, took 0.5267071723937988s- Accuracy=0.9802564102564103\n",
      "Iteration: 310, took 0.49341440200805664s- Accuracy=0.9804358974358974\n",
      "Iteration: 311, took 0.5053384304046631s- Accuracy=0.9804358974358974\n",
      "Iteration: 312, took 0.47039246559143066s- Accuracy=0.9801794871794872\n",
      "Iteration: 313, took 0.5211582183837891s- Accuracy=0.9802564102564103\n",
      "Iteration: 314, took 0.5409238338470459s- Accuracy=0.9804102564102564\n",
      "Iteration: 315, took 0.5959029197692871s- Accuracy=0.9804358974358974\n",
      "Iteration: 316, took 0.4442307949066162s- Accuracy=0.9805897435897436\n",
      "Iteration: 317, took 0.5744659900665283s- Accuracy=0.9807692307692307\n",
      "Iteration: 318, took 0.5032837390899658s- Accuracy=0.9806410256410256\n",
      "Iteration: 319, took 0.4987823963165283s- Accuracy=0.9806666666666667\n",
      "Iteration: 320, took 0.44306254386901855s- Accuracy=0.9804615384615385\n",
      "Iteration: 321, took 0.6008777618408203s- Accuracy=0.9807179487179487\n",
      "Iteration: 322, took 0.5093541145324707s- Accuracy=0.9800769230769231\n",
      "Iteration: 323, took 0.5168120861053467s- Accuracy=0.9805384615384616\n",
      "Iteration: 324, took 0.48560595512390137s- Accuracy=0.9806410256410256\n",
      "Iteration: 325, took 0.5075247287750244s- Accuracy=0.9804615384615385\n",
      "Iteration: 326, took 0.5249242782592773s- Accuracy=0.9803333333333333\n",
      "Iteration: 327, took 0.49661898612976074s- Accuracy=0.9804615384615385\n",
      "Iteration: 328, took 0.6578075885772705s- Accuracy=0.9805897435897436\n",
      "Iteration: 329, took 0.5490262508392334s- Accuracy=0.9807179487179487\n",
      "Iteration: 330, took 0.4919862747192383s- Accuracy=0.9804871794871794\n",
      "Iteration: 331, took 0.4675118923187256s- Accuracy=0.9805384615384616\n",
      "Iteration: 332, took 0.46006059646606445s- Accuracy=0.9803589743589743\n",
      "Iteration: 333, took 0.497067928314209s- Accuracy=0.9807948717948718\n",
      "Iteration: 334, took 0.48279714584350586s- Accuracy=0.9803846153846154\n",
      "Iteration: 335, took 0.4705226421356201s- Accuracy=0.9804615384615385\n",
      "Iteration: 336, took 0.4668419361114502s- Accuracy=0.9802820512820513\n",
      "Iteration: 337, took 0.48067355155944824s- Accuracy=0.9804615384615385\n",
      "Iteration: 338, took 0.4445528984069824s- Accuracy=0.9804358974358974\n",
      "Iteration: 339, took 0.46314573287963867s- Accuracy=0.9803589743589743\n",
      "Iteration: 340, took 0.4970085620880127s- Accuracy=0.9806153846153847\n",
      "Iteration: 341, took 0.45021653175354004s- Accuracy=0.9804615384615385\n",
      "Iteration: 342, took 0.4932892322540283s- Accuracy=0.9803589743589743\n",
      "Iteration: 343, took 0.487140417098999s- Accuracy=0.9802564102564103\n",
      "Iteration: 344, took 0.4803316593170166s- Accuracy=0.9803076923076923\n",
      "Iteration: 345, took 0.5144400596618652s- Accuracy=0.9802564102564103\n",
      "Iteration: 346, took 0.5043799877166748s- Accuracy=0.9806410256410256\n",
      "Iteration: 347, took 0.5634036064147949s- Accuracy=0.9804102564102564\n",
      "Iteration: 348, took 0.5189857482910156s- Accuracy=0.9805128205128205\n",
      "Iteration: 349, took 0.4695918560028076s- Accuracy=0.9802051282051282\n",
      "Iteration: 350, took 0.46816039085388184s- Accuracy=0.9803076923076923\n",
      "Iteration: 351, took 0.4649181365966797s- Accuracy=0.9804358974358974\n",
      "Iteration: 352, took 0.5353825092315674s- Accuracy=0.9806923076923076\n",
      "Iteration: 353, took 0.49376487731933594s- Accuracy=0.9804102564102564\n",
      "Iteration: 354, took 0.5542373657226562s- Accuracy=0.9806923076923076\n",
      "Iteration: 355, took 0.46093201637268066s- Accuracy=0.9805128205128205\n",
      "Iteration: 356, took 0.5862350463867188s- Accuracy=0.9808717948717949\n",
      "Iteration: 357, took 0.4508340358734131s- Accuracy=0.9802820512820513\n",
      "Iteration: 358, took 0.5046446323394775s- Accuracy=0.9807179487179487\n",
      "Iteration: 359, took 0.4876070022583008s- Accuracy=0.9802051282051282\n",
      "Iteration: 360, took 0.4797985553741455s- Accuracy=0.9805384615384616\n",
      "Iteration: 361, took 0.4304831027984619s- Accuracy=0.9808717948717949\n",
      "Iteration: 362, took 0.5402576923370361s- Accuracy=0.9805897435897436\n",
      "Iteration: 363, took 0.45784592628479004s- Accuracy=0.9808717948717949\n",
      "Iteration: 364, took 0.5006966590881348s- Accuracy=0.9807435897435898\n",
      "Iteration: 365, took 0.49996042251586914s- Accuracy=0.9804871794871794\n",
      "Iteration: 366, took 0.47495579719543457s- Accuracy=0.9805897435897436\n",
      "Iteration: 367, took 0.5255310535430908s- Accuracy=0.9805128205128205\n",
      "Iteration: 368, took 0.5401613712310791s- Accuracy=0.9803846153846154\n",
      "Iteration: 369, took 0.4995102882385254s- Accuracy=0.9805128205128205\n",
      "Iteration: 370, took 0.4964444637298584s- Accuracy=0.9804615384615385\n",
      "Iteration: 371, took 0.45789361000061035s- Accuracy=0.9805897435897436\n",
      "Iteration: 372, took 0.4995441436767578s- Accuracy=0.9804871794871794\n",
      "Iteration: 373, took 0.5034420490264893s- Accuracy=0.9807948717948718\n",
      "Iteration: 374, took 0.48833656311035156s- Accuracy=0.9803846153846154\n",
      "Iteration: 375, took 0.4773688316345215s- Accuracy=0.9804615384615385\n",
      "Iteration: 376, took 0.571213960647583s- Accuracy=0.9806923076923076\n",
      "Iteration: 377, took 0.5000932216644287s- Accuracy=0.9804871794871794\n",
      "Iteration: 378, took 0.5406203269958496s- Accuracy=0.980948717948718\n",
      "Iteration: 379, took 0.5264089107513428s- Accuracy=0.9809230769230769\n",
      "Iteration: 380, took 0.5308339595794678s- Accuracy=0.9807692307692307\n",
      "Iteration: 381, took 0.45339179039001465s- Accuracy=0.9803076923076923\n",
      "Iteration: 382, took 0.5037741661071777s- Accuracy=0.9804871794871794\n",
      "Iteration: 383, took 0.5800526142120361s- Accuracy=0.9805128205128205\n",
      "Iteration: 384, took 0.5156140327453613s- Accuracy=0.9808717948717949\n",
      "Iteration: 385, took 0.45488858222961426s- Accuracy=0.9803846153846154\n",
      "Iteration: 386, took 0.6362552642822266s- Accuracy=0.9804871794871794\n",
      "Iteration: 387, took 0.5046954154968262s- Accuracy=0.9806666666666667\n",
      "Iteration: 388, took 0.6176807880401611s- Accuracy=0.9806666666666667\n",
      "Iteration: 389, took 0.5217292308807373s- Accuracy=0.9805897435897436\n",
      "Iteration: 390, took 0.5237038135528564s- Accuracy=0.9807435897435898\n",
      "Iteration: 391, took 0.4788966178894043s- Accuracy=0.9807435897435898\n",
      "Iteration: 392, took 0.5000090599060059s- Accuracy=0.9805384615384616\n",
      "Iteration: 393, took 0.5353498458862305s- Accuracy=0.9807435897435898\n",
      "Iteration: 394, took 0.4917283058166504s- Accuracy=0.9805384615384616\n",
      "Iteration: 395, took 0.5494627952575684s- Accuracy=0.9807179487179487\n",
      "Iteration: 396, took 0.49829626083374023s- Accuracy=0.9806923076923076\n",
      "Iteration: 397, took 0.5350985527038574s- Accuracy=0.9806666666666667\n",
      "Iteration: 398, took 0.5072824954986572s- Accuracy=0.9806923076923076\n",
      "Iteration: 399, took 0.5038342475891113s- Accuracy=0.981025641025641\n",
      "Iteration: 400, took 0.4946267604827881s- Accuracy=0.9807948717948718\n",
      "Iteration: 401, took 0.546381950378418s- Accuracy=0.9804871794871794\n",
      "Iteration: 402, took 0.4857511520385742s- Accuracy=0.9807948717948718\n",
      "Iteration: 403, took 0.47840309143066406s- Accuracy=0.9809230769230769\n",
      "Iteration: 404, took 0.6037862300872803s- Accuracy=0.9804102564102564\n",
      "Iteration: 405, took 0.47858238220214844s- Accuracy=0.9806410256410256\n",
      "Iteration: 406, took 0.4691336154937744s- Accuracy=0.9804102564102564\n",
      "Iteration: 407, took 0.4790630340576172s- Accuracy=0.9807179487179487\n",
      "Iteration: 408, took 0.503216028213501s- Accuracy=0.9809230769230769\n",
      "Iteration: 409, took 0.4602701663970947s- Accuracy=0.9808205128205129\n",
      "Iteration: 410, took 0.5177395343780518s- Accuracy=0.9808205128205129\n",
      "Iteration: 411, took 0.5605700016021729s- Accuracy=0.9807948717948718\n",
      "Iteration: 412, took 0.5144059658050537s- Accuracy=0.9806153846153847\n",
      "Iteration: 413, took 0.4822254180908203s- Accuracy=0.981025641025641\n",
      "Iteration: 414, took 0.5071561336517334s- Accuracy=0.980948717948718\n",
      "Iteration: 415, took 0.4900989532470703s- Accuracy=0.9805128205128205\n",
      "Iteration: 416, took 0.46352148056030273s- Accuracy=0.9808461538461538\n",
      "Iteration: 417, took 0.5134909152984619s- Accuracy=0.9805641025641025\n",
      "Iteration: 418, took 0.5093362331390381s- Accuracy=0.9811794871794872\n",
      "Iteration: 419, took 0.4985315799713135s- Accuracy=0.9806153846153847\n",
      "Iteration: 420, took 0.5082309246063232s- Accuracy=0.9811025641025641\n",
      "Iteration: 421, took 0.4821641445159912s- Accuracy=0.9811025641025641\n",
      "Iteration: 422, took 0.49948859214782715s- Accuracy=0.9811794871794872\n",
      "Iteration: 423, took 0.48824334144592285s- Accuracy=0.9807692307692307\n",
      "Iteration: 424, took 0.5332729816436768s- Accuracy=0.980948717948718\n",
      "Iteration: 425, took 0.6030328273773193s- Accuracy=0.981025641025641\n",
      "Iteration: 426, took 0.4676492214202881s- Accuracy=0.9812564102564103\n",
      "Iteration: 427, took 0.44672131538391113s- Accuracy=0.9806666666666667\n",
      "Iteration: 428, took 0.5760202407836914s- Accuracy=0.981\n",
      "Iteration: 429, took 0.5048666000366211s- Accuracy=0.981051282051282\n",
      "Iteration: 430, took 0.5021052360534668s- Accuracy=0.9809230769230769\n",
      "Iteration: 431, took 0.5293464660644531s- Accuracy=0.9811794871794872\n",
      "Iteration: 432, took 0.6376309394836426s- Accuracy=0.9808205128205129\n",
      "Iteration: 433, took 0.47693753242492676s- Accuracy=0.9805897435897436\n",
      "Iteration: 434, took 0.5377295017242432s- Accuracy=0.9813076923076923\n",
      "Iteration: 435, took 0.5746610164642334s- Accuracy=0.9811025641025641\n",
      "Iteration: 436, took 0.5094707012176514s- Accuracy=0.9811282051282051\n",
      "Iteration: 437, took 0.5880429744720459s- Accuracy=0.9809230769230769\n",
      "Iteration: 438, took 0.5717825889587402s- Accuracy=0.9807179487179487\n",
      "Iteration: 439, took 0.5101318359375s- Accuracy=0.9812051282051282\n",
      "Iteration: 440, took 0.5082685947418213s- Accuracy=0.980974358974359\n",
      "Iteration: 441, took 0.569155216217041s- Accuracy=0.9809230769230769\n",
      "Iteration: 442, took 0.5316908359527588s- Accuracy=0.981025641025641\n",
      "Iteration: 443, took 0.42989444732666016s- Accuracy=0.9809230769230769\n",
      "Iteration: 444, took 0.5762805938720703s- Accuracy=0.9807692307692307\n",
      "Iteration: 445, took 0.5898067951202393s- Accuracy=0.9807948717948718\n",
      "Iteration: 446, took 0.7236275672912598s- Accuracy=0.9810769230769231\n",
      "Iteration: 447, took 0.5343937873840332s- Accuracy=0.9810769230769231\n",
      "Iteration: 448, took 0.5655767917633057s- Accuracy=0.9808717948717949\n",
      "Iteration: 449, took 0.4883749485015869s- Accuracy=0.9808205128205129\n",
      "Iteration: 450, took 0.5387444496154785s- Accuracy=0.9806666666666667\n",
      "Iteration: 451, took 0.45822739601135254s- Accuracy=0.9811794871794872\n",
      "Iteration: 452, took 0.5223088264465332s- Accuracy=0.9806923076923076\n",
      "Iteration: 453, took 0.5026769638061523s- Accuracy=0.9811538461538462\n",
      "Iteration: 454, took 0.5093562602996826s- Accuracy=0.9807692307692307\n",
      "Iteration: 455, took 0.4650230407714844s- Accuracy=0.9811538461538462\n",
      "Iteration: 456, took 0.5686964988708496s- Accuracy=0.9811025641025641\n",
      "Iteration: 457, took 0.48325133323669434s- Accuracy=0.9814358974358974\n",
      "Iteration: 458, took 0.4907655715942383s- Accuracy=0.9812051282051282\n",
      "Iteration: 459, took 0.5173578262329102s- Accuracy=0.981\n",
      "Iteration: 460, took 0.5163366794586182s- Accuracy=0.9810769230769231\n",
      "Iteration: 461, took 0.502880334854126s- Accuracy=0.9811282051282051\n",
      "Iteration: 462, took 0.49974703788757324s- Accuracy=0.9810769230769231\n",
      "Iteration: 463, took 0.48175930976867676s- Accuracy=0.9812051282051282\n",
      "Iteration: 464, took 0.548393964767456s- Accuracy=0.9811282051282051\n",
      "Iteration: 465, took 0.5124645233154297s- Accuracy=0.9812307692307692\n",
      "Iteration: 466, took 0.6667928695678711s- Accuracy=0.9812051282051282\n",
      "Iteration: 467, took 0.5208859443664551s- Accuracy=0.9812051282051282\n",
      "Iteration: 468, took 0.4848487377166748s- Accuracy=0.9808461538461538\n",
      "Iteration: 469, took 0.4938664436340332s- Accuracy=0.981025641025641\n",
      "Iteration: 470, took 0.45647478103637695s- Accuracy=0.9813589743589743\n",
      "Iteration: 471, took 0.5000834465026855s- Accuracy=0.9807692307692307\n",
      "Iteration: 472, took 0.5624954700469971s- Accuracy=0.9814871794871795\n",
      "Iteration: 473, took 0.5628175735473633s- Accuracy=0.981025641025641\n",
      "Iteration: 474, took 0.5407052040100098s- Accuracy=0.9811282051282051\n",
      "Iteration: 475, took 0.5488848686218262s- Accuracy=0.9807948717948718\n",
      "Iteration: 476, took 0.4783012866973877s- Accuracy=0.9811794871794872\n",
      "Iteration: 477, took 0.4978220462799072s- Accuracy=0.9811025641025641\n",
      "Iteration: 478, took 0.47275853157043457s- Accuracy=0.980974358974359\n",
      "Iteration: 479, took 0.4845585823059082s- Accuracy=0.9812307692307692\n",
      "Iteration: 480, took 0.4836599826812744s- Accuracy=0.9809230769230769\n",
      "Iteration: 481, took 0.5579001903533936s- Accuracy=0.9811025641025641\n",
      "Iteration: 482, took 0.5326459407806396s- Accuracy=0.9808205128205129\n",
      "Iteration: 483, took 0.5192890167236328s- Accuracy=0.9811282051282051\n",
      "Iteration: 484, took 0.47385239601135254s- Accuracy=0.9812564102564103\n",
      "Iteration: 485, took 0.4778470993041992s- Accuracy=0.9812820512820513\n",
      "Iteration: 486, took 0.4473228454589844s- Accuracy=0.9813589743589743\n",
      "Iteration: 487, took 0.4853236675262451s- Accuracy=0.981025641025641\n",
      "Iteration: 488, took 0.4808053970336914s- Accuracy=0.981\n",
      "Iteration: 489, took 0.4660627841949463s- Accuracy=0.9813333333333333\n",
      "Iteration: 490, took 0.48905253410339355s- Accuracy=0.9812307692307692\n",
      "Iteration: 491, took 0.4820687770843506s- Accuracy=0.9812051282051282\n",
      "Iteration: 492, took 0.4798550605773926s- Accuracy=0.981051282051282\n",
      "Iteration: 493, took 0.5266702175140381s- Accuracy=0.9811025641025641\n",
      "Iteration: 494, took 0.5061955451965332s- Accuracy=0.9812051282051282\n",
      "Iteration: 495, took 0.5073032379150391s- Accuracy=0.9812051282051282\n",
      "Iteration: 496, took 0.5483791828155518s- Accuracy=0.9809230769230769\n",
      "Iteration: 497, took 0.5438461303710938s- Accuracy=0.9812564102564103\n",
      "Iteration: 498, took 0.5426938533782959s- Accuracy=0.9811538461538462\n",
      "Iteration: 499, took 0.47232794761657715s- Accuracy=0.9813333333333333\n",
      "Iteration: 500, took 0.5337119102478027s- Accuracy=0.9813333333333333\n",
      "Iteration: 501, took 0.4608142375946045s- Accuracy=0.980974358974359\n",
      "Iteration: 502, took 0.4738194942474365s- Accuracy=0.9813076923076923\n",
      "Iteration: 503, took 0.48277807235717773s- Accuracy=0.981051282051282\n",
      "Iteration: 504, took 0.5254597663879395s- Accuracy=0.9813846153846154\n",
      "Iteration: 505, took 0.44704151153564453s- Accuracy=0.9812820512820513\n",
      "Iteration: 506, took 0.4638340473175049s- Accuracy=0.9813333333333333\n",
      "Iteration: 507, took 0.526439905166626s- Accuracy=0.9812307692307692\n",
      "Iteration: 508, took 0.5202312469482422s- Accuracy=0.9815384615384616\n",
      "Iteration: 509, took 0.43485546112060547s- Accuracy=0.9814871794871795\n",
      "Iteration: 510, took 0.5672862529754639s- Accuracy=0.9812820512820513\n",
      "Iteration: 511, took 0.5945367813110352s- Accuracy=0.9811794871794872\n",
      "Iteration: 512, took 0.489520788192749s- Accuracy=0.980974358974359\n",
      "Iteration: 513, took 0.4610404968261719s- Accuracy=0.9812564102564103\n",
      "Iteration: 514, took 0.47156858444213867s- Accuracy=0.9813333333333333\n",
      "Iteration: 515, took 0.4644505977630615s- Accuracy=0.9814358974358974\n",
      "Iteration: 516, took 0.5737090110778809s- Accuracy=0.9811025641025641\n",
      "Iteration: 517, took 0.468782901763916s- Accuracy=0.9816153846153847\n",
      "Iteration: 518, took 0.5870628356933594s- Accuracy=0.9813589743589743\n",
      "Iteration: 519, took 0.4675450325012207s- Accuracy=0.9815128205128205\n",
      "Iteration: 520, took 0.4374394416809082s- Accuracy=0.9814871794871795\n",
      "Iteration: 521, took 0.45887231826782227s- Accuracy=0.9814358974358974\n",
      "Iteration: 522, took 0.5142462253570557s- Accuracy=0.9814358974358974\n",
      "Iteration: 523, took 0.4608433246612549s- Accuracy=0.9818205128205129\n",
      "Iteration: 524, took 0.4842660427093506s- Accuracy=0.9812307692307692\n",
      "Iteration: 525, took 0.4751303195953369s- Accuracy=0.9813589743589743\n",
      "Iteration: 526, took 0.4459998607635498s- Accuracy=0.9816410256410256\n",
      "Iteration: 527, took 0.5146429538726807s- Accuracy=0.9813846153846154\n",
      "Iteration: 528, took 0.5123124122619629s- Accuracy=0.9814615384615385\n",
      "Iteration: 529, took 0.4959592819213867s- Accuracy=0.9815128205128205\n",
      "Iteration: 530, took 0.5661263465881348s- Accuracy=0.9815641025641025\n",
      "Iteration: 531, took 0.48592686653137207s- Accuracy=0.9816923076923076\n",
      "Iteration: 532, took 0.5420486927032471s- Accuracy=0.9815641025641025\n",
      "Iteration: 533, took 0.49303507804870605s- Accuracy=0.9813846153846154\n",
      "Iteration: 534, took 0.5373072624206543s- Accuracy=0.9816410256410256\n",
      "Iteration: 535, took 0.5389056205749512s- Accuracy=0.9813846153846154\n",
      "Iteration: 536, took 0.4734382629394531s- Accuracy=0.9818205128205129\n",
      "Iteration: 537, took 0.46729016304016113s- Accuracy=0.9816410256410256\n",
      "Iteration: 538, took 0.4427666664123535s- Accuracy=0.9814615384615385\n",
      "Iteration: 539, took 0.4713859558105469s- Accuracy=0.9817435897435898\n",
      "Iteration: 540, took 0.45381832122802734s- Accuracy=0.9817692307692307\n",
      "Iteration: 541, took 0.4941847324371338s- Accuracy=0.9817948717948718\n",
      "Iteration: 542, took 0.5853943824768066s- Accuracy=0.9813333333333333\n",
      "Iteration: 543, took 0.5043244361877441s- Accuracy=0.9819230769230769\n",
      "Iteration: 544, took 0.5001168251037598s- Accuracy=0.9815128205128205\n",
      "Iteration: 545, took 0.547311544418335s- Accuracy=0.9816923076923076\n",
      "Iteration: 546, took 0.49041223526000977s- Accuracy=0.9814102564102564\n",
      "Iteration: 547, took 0.535428524017334s- Accuracy=0.982\n",
      "Iteration: 548, took 0.5458157062530518s- Accuracy=0.981974358974359\n",
      "Iteration: 549, took 0.5046980381011963s- Accuracy=0.9815897435897436\n",
      "Iteration: 550, took 0.47084617614746094s- Accuracy=0.981948717948718\n",
      "Iteration: 551, took 0.5068314075469971s- Accuracy=0.9814615384615385\n",
      "Iteration: 552, took 0.4938161373138428s- Accuracy=0.9815641025641025\n",
      "Iteration: 553, took 0.4927389621734619s- Accuracy=0.9818974358974359\n",
      "Iteration: 554, took 0.4596700668334961s- Accuracy=0.9817948717948718\n",
      "Iteration: 555, took 0.4929344654083252s- Accuracy=0.9815641025641025\n",
      "Iteration: 556, took 0.5155336856842041s- Accuracy=0.9817948717948718\n",
      "Iteration: 557, took 0.45128631591796875s- Accuracy=0.9816410256410256\n",
      "Iteration: 558, took 0.4767158031463623s- Accuracy=0.9816666666666667\n",
      "Iteration: 559, took 0.47690343856811523s- Accuracy=0.9817692307692307\n",
      "Iteration: 560, took 0.47872471809387207s- Accuracy=0.982051282051282\n",
      "Iteration: 561, took 0.5108799934387207s- Accuracy=0.9819230769230769\n",
      "Iteration: 562, took 0.4510657787322998s- Accuracy=0.9815641025641025\n",
      "Iteration: 563, took 0.4749031066894531s- Accuracy=0.9816923076923076\n",
      "Iteration: 564, took 0.4920048713684082s- Accuracy=0.9816923076923076\n",
      "Iteration: 565, took 0.4482605457305908s- Accuracy=0.9815384615384616\n",
      "Iteration: 566, took 0.4897732734680176s- Accuracy=0.9818205128205129\n",
      "Iteration: 567, took 0.5246446132659912s- Accuracy=0.982025641025641\n",
      "Iteration: 568, took 0.47204113006591797s- Accuracy=0.9817179487179487\n",
      "Iteration: 569, took 0.49782228469848633s- Accuracy=0.9814615384615385\n",
      "Iteration: 570, took 0.4879143238067627s- Accuracy=0.9818461538461538\n",
      "Iteration: 571, took 0.49181556701660156s- Accuracy=0.9819230769230769\n",
      "Iteration: 572, took 0.4648740291595459s- Accuracy=0.9818974358974359\n",
      "Iteration: 573, took 0.48714637756347656s- Accuracy=0.9824358974358974\n",
      "Iteration: 574, took 0.465761661529541s- Accuracy=0.9818974358974359\n",
      "Iteration: 575, took 0.4819619655609131s- Accuracy=0.9818717948717949\n",
      "Iteration: 576, took 0.4431753158569336s- Accuracy=0.9815897435897436\n",
      "Iteration: 577, took 0.5018665790557861s- Accuracy=0.9821794871794872\n",
      "Iteration: 578, took 0.491771936416626s- Accuracy=0.9818461538461538\n",
      "Iteration: 579, took 0.49987077713012695s- Accuracy=0.9818205128205129\n",
      "Iteration: 580, took 0.5019145011901855s- Accuracy=0.9817948717948718\n",
      "Iteration: 581, took 0.4739871025085449s- Accuracy=0.9818717948717949\n",
      "Iteration: 582, took 0.4778711795806885s- Accuracy=0.9817179487179487\n",
      "Iteration: 583, took 0.4905064105987549s- Accuracy=0.9818717948717949\n",
      "Iteration: 584, took 0.4958369731903076s- Accuracy=0.9817692307692307\n",
      "Iteration: 585, took 0.4761178493499756s- Accuracy=0.9818461538461538\n",
      "Iteration: 586, took 0.4759330749511719s- Accuracy=0.981948717948718\n",
      "Iteration: 587, took 0.5038783550262451s- Accuracy=0.982\n",
      "Iteration: 588, took 0.4788784980773926s- Accuracy=0.9817692307692307\n",
      "Iteration: 589, took 0.45610976219177246s- Accuracy=0.982051282051282\n",
      "Iteration: 590, took 0.5028188228607178s- Accuracy=0.9816410256410256\n",
      "Iteration: 591, took 0.46078968048095703s- Accuracy=0.982051282051282\n",
      "Iteration: 592, took 0.4719657897949219s- Accuracy=0.9818974358974359\n",
      "Iteration: 593, took 0.4854295253753662s- Accuracy=0.9813846153846154\n",
      "Iteration: 594, took 0.46610236167907715s- Accuracy=0.981974358974359\n",
      "Iteration: 595, took 0.4816434383392334s- Accuracy=0.9818461538461538\n",
      "Iteration: 596, took 0.47386646270751953s- Accuracy=0.982\n",
      "Iteration: 597, took 0.49465394020080566s- Accuracy=0.9821025641025641\n",
      "Iteration: 598, took 0.46210289001464844s- Accuracy=0.9816666666666667\n",
      "Iteration: 599, took 0.4776618480682373s- Accuracy=0.9822820512820513\n",
      "Iteration: 600, took 0.4516739845275879s- Accuracy=0.9817435897435898\n",
      "Iteration: 601, took 0.5013875961303711s- Accuracy=0.982051282051282\n",
      "Iteration: 602, took 0.5793170928955078s- Accuracy=0.981948717948718\n",
      "Iteration: 603, took 0.5000307559967041s- Accuracy=0.982025641025641\n",
      "Iteration: 604, took 0.5363225936889648s- Accuracy=0.9815897435897436\n",
      "Iteration: 605, took 0.4660604000091553s- Accuracy=0.9818205128205129\n",
      "Iteration: 606, took 0.48174142837524414s- Accuracy=0.9816923076923076\n",
      "Iteration: 607, took 0.5298399925231934s- Accuracy=0.9822564102564103\n",
      "Iteration: 608, took 0.5085926055908203s- Accuracy=0.9818205128205129\n",
      "Iteration: 609, took 0.47702765464782715s- Accuracy=0.9817435897435898\n",
      "Iteration: 610, took 0.4543476104736328s- Accuracy=0.9818717948717949\n",
      "Iteration: 611, took 0.4637949466705322s- Accuracy=0.9818205128205129\n",
      "Iteration: 612, took 0.4456183910369873s- Accuracy=0.982051282051282\n",
      "Iteration: 613, took 0.5044350624084473s- Accuracy=0.9817179487179487\n",
      "Iteration: 614, took 0.46785902976989746s- Accuracy=0.9817948717948718\n",
      "Iteration: 615, took 0.5099062919616699s- Accuracy=0.981948717948718\n",
      "Iteration: 616, took 0.46021556854248047s- Accuracy=0.9821025641025641\n",
      "Iteration: 617, took 0.5586135387420654s- Accuracy=0.9821025641025641\n",
      "Iteration: 618, took 0.48687100410461426s- Accuracy=0.9822307692307692\n",
      "Iteration: 619, took 0.48713040351867676s- Accuracy=0.982051282051282\n",
      "Iteration: 620, took 0.44995784759521484s- Accuracy=0.9822820512820513\n",
      "Iteration: 621, took 0.5165855884552002s- Accuracy=0.9823333333333333\n",
      "Iteration: 622, took 0.4863431453704834s- Accuracy=0.982025641025641\n",
      "Iteration: 623, took 0.5305690765380859s- Accuracy=0.9821282051282051\n",
      "Iteration: 624, took 0.47438526153564453s- Accuracy=0.982025641025641\n",
      "Iteration: 625, took 0.5347380638122559s- Accuracy=0.982\n",
      "Iteration: 626, took 0.4671134948730469s- Accuracy=0.9818205128205129\n",
      "Iteration: 627, took 0.4974696636199951s- Accuracy=0.9822051282051282\n",
      "Iteration: 628, took 0.4524989128112793s- Accuracy=0.9821538461538462\n",
      "Iteration: 629, took 0.475527286529541s- Accuracy=0.9822564102564103\n",
      "Iteration: 630, took 0.5119197368621826s- Accuracy=0.9822051282051282\n",
      "Iteration: 631, took 0.46626901626586914s- Accuracy=0.9823076923076923\n",
      "Iteration: 632, took 0.5318448543548584s- Accuracy=0.9817948717948718\n",
      "Iteration: 633, took 0.5218315124511719s- Accuracy=0.9825641025641025\n",
      "Iteration: 634, took 0.47310733795166016s- Accuracy=0.9820769230769231\n",
      "Iteration: 635, took 0.49986696243286133s- Accuracy=0.9822051282051282\n",
      "Iteration: 636, took 0.4830322265625s- Accuracy=0.982\n",
      "Iteration: 637, took 0.5117838382720947s- Accuracy=0.9821538461538462\n",
      "Iteration: 638, took 0.5265648365020752s- Accuracy=0.981948717948718\n",
      "Iteration: 639, took 0.4331235885620117s- Accuracy=0.982\n",
      "Iteration: 640, took 0.45092129707336426s- Accuracy=0.9822307692307692\n",
      "Iteration: 641, took 0.4820737838745117s- Accuracy=0.982025641025641\n",
      "Iteration: 642, took 0.4825432300567627s- Accuracy=0.982025641025641\n",
      "Iteration: 643, took 0.4738583564758301s- Accuracy=0.9816923076923076\n",
      "Iteration: 644, took 0.5156025886535645s- Accuracy=0.982\n",
      "Iteration: 645, took 0.4902465343475342s- Accuracy=0.9817948717948718\n",
      "Iteration: 646, took 0.4787900447845459s- Accuracy=0.9822564102564103\n",
      "Iteration: 647, took 0.4883859157562256s- Accuracy=0.981948717948718\n",
      "Iteration: 648, took 0.49530029296875s- Accuracy=0.9818974358974359\n",
      "Iteration: 649, took 0.5034425258636475s- Accuracy=0.9816410256410256\n",
      "Iteration: 650, took 0.5437896251678467s- Accuracy=0.9818974358974359\n",
      "Iteration: 651, took 0.4701118469238281s- Accuracy=0.981974358974359\n",
      "Iteration: 652, took 0.4690439701080322s- Accuracy=0.9819230769230769\n",
      "Iteration: 653, took 0.5260224342346191s- Accuracy=0.981948717948718\n",
      "Iteration: 654, took 0.5216693878173828s- Accuracy=0.982\n",
      "Iteration: 655, took 0.519061803817749s- Accuracy=0.9817948717948718\n",
      "Iteration: 656, took 0.6023063659667969s- Accuracy=0.9817692307692307\n",
      "Iteration: 657, took 0.47518229484558105s- Accuracy=0.9822051282051282\n",
      "Iteration: 658, took 0.6427500247955322s- Accuracy=0.9818717948717949\n",
      "Iteration: 659, took 0.5270311832427979s- Accuracy=0.9816666666666667\n",
      "Iteration: 660, took 0.5171473026275635s- Accuracy=0.9819230769230769\n",
      "Iteration: 661, took 0.4785728454589844s- Accuracy=0.9814871794871795\n",
      "Iteration: 662, took 0.4809567928314209s- Accuracy=0.982051282051282\n",
      "Iteration: 663, took 0.4495503902435303s- Accuracy=0.9816923076923076\n",
      "Iteration: 664, took 0.5715546607971191s- Accuracy=0.9819230769230769\n",
      "Iteration: 665, took 0.5191216468811035s- Accuracy=0.9817179487179487\n",
      "Iteration: 666, took 0.490570068359375s- Accuracy=0.981974358974359\n",
      "Iteration: 667, took 0.4598267078399658s- Accuracy=0.9818717948717949\n",
      "Iteration: 668, took 0.5907711982727051s- Accuracy=0.9816666666666667\n",
      "Iteration: 669, took 0.48197126388549805s- Accuracy=0.9818461538461538\n",
      "Iteration: 670, took 0.5067641735076904s- Accuracy=0.9818205128205129\n",
      "Iteration: 671, took 0.555778980255127s- Accuracy=0.982025641025641\n",
      "Iteration: 672, took 0.545792818069458s- Accuracy=0.9821282051282051\n",
      "Iteration: 673, took 0.5094614028930664s- Accuracy=0.9817435897435898\n",
      "Iteration: 674, took 0.5808556079864502s- Accuracy=0.9817692307692307\n",
      "Iteration: 675, took 0.47960734367370605s- Accuracy=0.9817435897435898\n",
      "Iteration: 676, took 0.507936954498291s- Accuracy=0.9817948717948718\n",
      "Iteration: 677, took 0.4796128273010254s- Accuracy=0.9818205128205129\n",
      "Iteration: 678, took 0.5080480575561523s- Accuracy=0.9821025641025641\n",
      "Iteration: 679, took 0.5371546745300293s- Accuracy=0.9817692307692307\n",
      "Iteration: 680, took 0.5422558784484863s- Accuracy=0.9815641025641025\n",
      "Iteration: 681, took 0.4895477294921875s- Accuracy=0.9818974358974359\n",
      "Iteration: 682, took 0.5465054512023926s- Accuracy=0.9816410256410256\n",
      "Iteration: 683, took 0.5057623386383057s- Accuracy=0.9818717948717949\n",
      "Iteration: 684, took 0.5482161045074463s- Accuracy=0.9815128205128205\n",
      "Iteration: 685, took 0.5718004703521729s- Accuracy=0.9816153846153847\n",
      "Iteration: 686, took 0.4817774295806885s- Accuracy=0.9816923076923076\n",
      "Iteration: 687, took 0.5584216117858887s- Accuracy=0.9817692307692307\n",
      "Iteration: 688, took 0.5860545635223389s- Accuracy=0.9818974358974359\n",
      "Iteration: 689, took 0.4776570796966553s- Accuracy=0.9819230769230769\n",
      "Iteration: 690, took 0.4686882495880127s- Accuracy=0.982\n",
      "Iteration: 691, took 0.44150686264038086s- Accuracy=0.981974358974359\n",
      "Iteration: 692, took 0.4881923198699951s- Accuracy=0.982025641025641\n",
      "Iteration: 693, took 0.4855034351348877s- Accuracy=0.9820769230769231\n",
      "Iteration: 694, took 0.49187493324279785s- Accuracy=0.9817692307692307\n",
      "Iteration: 695, took 0.47719240188598633s- Accuracy=0.9818717948717949\n",
      "Iteration: 696, took 0.5110352039337158s- Accuracy=0.9817948717948718\n",
      "Iteration: 697, took 0.4983954429626465s- Accuracy=0.9818205128205129\n",
      "Iteration: 698, took 0.46739673614501953s- Accuracy=0.982\n",
      "Iteration: 699, took 0.47771644592285156s- Accuracy=0.9818205128205129\n",
      "Iteration: 700, took 0.5751183032989502s- Accuracy=0.9822820512820513\n",
      "Iteration: 701, took 0.4630899429321289s- Accuracy=0.9818205128205129\n",
      "Iteration: 702, took 0.5172293186187744s- Accuracy=0.9817179487179487\n",
      "Iteration: 703, took 0.4700002670288086s- Accuracy=0.982\n",
      "Iteration: 704, took 0.516770601272583s- Accuracy=0.9818974358974359\n",
      "Iteration: 705, took 0.4386324882507324s- Accuracy=0.9817435897435898\n",
      "Iteration: 706, took 0.3367929458618164s- Accuracy=0.9817435897435898\n",
      "Iteration: 707, took 0.19898629188537598s- Accuracy=0.9819230769230769\n",
      "Iteration: 708, took 0.5108785629272461s- Accuracy=0.9821025641025641\n",
      "Iteration: 709, took 0.4319939613342285s- Accuracy=0.981974358974359\n",
      "Iteration: 710, took 0.47182798385620117s- Accuracy=0.9818205128205129\n",
      "Iteration: 711, took 0.497114896774292s- Accuracy=0.9817948717948718\n",
      "Iteration: 712, took 0.49118924140930176s- Accuracy=0.9818205128205129\n",
      "Iteration: 713, took 0.487290620803833s- Accuracy=0.9817435897435898\n",
      "Iteration: 714, took 0.4953956604003906s- Accuracy=0.9816666666666667\n",
      "Iteration: 715, took 0.5095930099487305s- Accuracy=0.9816666666666667\n",
      "Iteration: 716, took 0.49522948265075684s- Accuracy=0.9817179487179487\n",
      "Iteration: 717, took 0.463637113571167s- Accuracy=0.982025641025641\n",
      "Iteration: 718, took 0.5632450580596924s- Accuracy=0.9816923076923076\n",
      "Iteration: 719, took 0.49613332748413086s- Accuracy=0.9819230769230769\n",
      "Iteration: 720, took 0.46702051162719727s- Accuracy=0.9817435897435898\n",
      "Iteration: 721, took 0.5143256187438965s- Accuracy=0.9817948717948718\n",
      "Iteration: 722, took 0.47522926330566406s- Accuracy=0.9817692307692307\n",
      "Iteration: 723, took 0.45705580711364746s- Accuracy=0.9817948717948718\n",
      "Iteration: 724, took 0.4492518901824951s- Accuracy=0.9816923076923076\n",
      "Iteration: 725, took 0.4987473487854004s- Accuracy=0.9817692307692307\n",
      "Iteration: 726, took 0.4886312484741211s- Accuracy=0.9816153846153847\n",
      "Iteration: 727, took 0.4862048625946045s- Accuracy=0.9816410256410256\n",
      "Iteration: 728, took 0.4588637351989746s- Accuracy=0.9814615384615385\n",
      "Iteration: 729, took 0.48926854133605957s- Accuracy=0.982\n",
      "Iteration: 730, took 0.46073102951049805s- Accuracy=0.9817435897435898\n",
      "Iteration: 731, took 0.5182933807373047s- Accuracy=0.9814871794871795\n",
      "Iteration: 732, took 0.4624059200286865s- Accuracy=0.9816923076923076\n",
      "Iteration: 733, took 0.5432653427124023s- Accuracy=0.9815128205128205\n",
      "Iteration: 734, took 0.458986759185791s- Accuracy=0.9817179487179487\n",
      "Iteration: 735, took 0.4934859275817871s- Accuracy=0.9817179487179487\n",
      "Iteration: 736, took 0.4879577159881592s- Accuracy=0.9815641025641025\n",
      "Iteration: 737, took 0.516333818435669s- Accuracy=0.9814871794871795\n",
      "Iteration: 738, took 0.44141626358032227s- Accuracy=0.9817692307692307\n",
      "Iteration: 739, took 0.4951744079589844s- Accuracy=0.9813846153846154\n",
      "Iteration: 740, took 0.43637704849243164s- Accuracy=0.9817692307692307\n",
      "Iteration: 741, took 0.48980093002319336s- Accuracy=0.9811538461538462\n",
      "Iteration: 742, took 0.530731201171875s- Accuracy=0.9817179487179487\n",
      "Iteration: 743, took 0.48145580291748047s- Accuracy=0.9815641025641025\n",
      "Iteration: 744, took 0.5060806274414062s- Accuracy=0.9816666666666667\n",
      "Iteration: 745, took 0.47095441818237305s- Accuracy=0.9817179487179487\n",
      "Iteration: 746, took 0.48654699325561523s- Accuracy=0.9816666666666667\n",
      "Iteration: 747, took 0.4405665397644043s- Accuracy=0.9818205128205129\n",
      "Iteration: 748, took 0.5004756450653076s- Accuracy=0.9814871794871795\n",
      "Iteration: 749, took 0.5021066665649414s- Accuracy=0.9816666666666667\n",
      "Iteration: 750, took 0.530210018157959s- Accuracy=0.9816923076923076\n",
      "Iteration: 751, took 0.6238250732421875s- Accuracy=0.9813589743589743\n",
      "Iteration: 752, took 0.594825029373169s- Accuracy=0.9816923076923076\n",
      "Iteration: 753, took 0.4986002445220947s- Accuracy=0.9817692307692307\n",
      "Iteration: 754, took 0.6276488304138184s- Accuracy=0.9817948717948718\n",
      "Iteration: 755, took 0.4721524715423584s- Accuracy=0.9818205128205129\n",
      "Iteration: 756, took 0.5085532665252686s- Accuracy=0.982\n",
      "Iteration: 757, took 0.5275657176971436s- Accuracy=0.9814102564102564\n",
      "Iteration: 758, took 0.4723973274230957s- Accuracy=0.9814871794871795\n",
      "Iteration: 759, took 0.48844194412231445s- Accuracy=0.9818205128205129\n",
      "Iteration: 760, took 0.42742395401000977s- Accuracy=0.982025641025641\n",
      "Iteration: 761, took 0.4849264621734619s- Accuracy=0.9815641025641025\n",
      "Iteration: 762, took 0.48488926887512207s- Accuracy=0.9822051282051282\n",
      "Iteration: 763, took 0.4583263397216797s- Accuracy=0.9817435897435898\n",
      "Iteration: 764, took 0.487133264541626s- Accuracy=0.9818461538461538\n",
      "Iteration: 765, took 0.5533041954040527s- Accuracy=0.9818974358974359\n",
      "Iteration: 766, took 0.5069773197174072s- Accuracy=0.9818717948717949\n",
      "Iteration: 767, took 0.4588789939880371s- Accuracy=0.9819230769230769\n",
      "Iteration: 768, took 0.4982466697692871s- Accuracy=0.9816153846153847\n",
      "Iteration: 769, took 0.4864315986633301s- Accuracy=0.9818461538461538\n",
      "Iteration: 770, took 0.4840717315673828s- Accuracy=0.981948717948718\n",
      "Iteration: 771, took 0.4465057849884033s- Accuracy=0.9817948717948718\n",
      "Iteration: 772, took 0.48907971382141113s- Accuracy=0.9814102564102564\n",
      "Iteration: 773, took 0.43998193740844727s- Accuracy=0.981974358974359\n",
      "Iteration: 774, took 0.5391116142272949s- Accuracy=0.9816923076923076\n",
      "Iteration: 775, took 0.454448938369751s- Accuracy=0.9818461538461538\n",
      "Iteration: 776, took 0.46529126167297363s- Accuracy=0.981948717948718\n",
      "Iteration: 777, took 0.4645118713378906s- Accuracy=0.9818717948717949\n",
      "Iteration: 778, took 0.5211126804351807s- Accuracy=0.9818974358974359\n",
      "Iteration: 779, took 0.4882955551147461s- Accuracy=0.9816153846153847\n",
      "Iteration: 780, took 0.5081567764282227s- Accuracy=0.9817435897435898\n",
      "Iteration: 781, took 0.4876275062561035s- Accuracy=0.9818205128205129\n",
      "Iteration: 782, took 0.5340192317962646s- Accuracy=0.9816153846153847\n",
      "Iteration: 783, took 0.4759199619293213s- Accuracy=0.9817692307692307\n",
      "Iteration: 784, took 0.48940396308898926s- Accuracy=0.9818461538461538\n",
      "Iteration: 785, took 0.5162353515625s- Accuracy=0.9816410256410256\n",
      "Iteration: 786, took 0.5705320835113525s- Accuracy=0.9818974358974359\n",
      "Iteration: 787, took 0.5423188209533691s- Accuracy=0.9816666666666667\n",
      "Iteration: 788, took 0.5196866989135742s- Accuracy=0.9815384615384616\n",
      "Iteration: 789, took 0.5207409858703613s- Accuracy=0.9817948717948718\n",
      "Iteration: 790, took 0.561776876449585s- Accuracy=0.9817692307692307\n",
      "Iteration: 791, took 0.5527002811431885s- Accuracy=0.9818205128205129\n",
      "Iteration: 792, took 0.5098719596862793s- Accuracy=0.9817435897435898\n",
      "Iteration: 793, took 0.45732712745666504s- Accuracy=0.9817948717948718\n",
      "Iteration: 794, took 0.46840476989746094s- Accuracy=0.9814102564102564\n",
      "Iteration: 795, took 0.5625479221343994s- Accuracy=0.9813333333333333\n",
      "Iteration: 796, took 0.5117261409759521s- Accuracy=0.9818205128205129\n",
      "Iteration: 797, took 0.4802727699279785s- Accuracy=0.981948717948718\n",
      "Iteration: 798, took 0.534466028213501s- Accuracy=0.9817179487179487\n",
      "Iteration: 799, took 0.447216272354126s- Accuracy=0.9814102564102564\n",
      "Iteration: 800, took 0.2492842674255371s- Accuracy=0.9817435897435898\n",
      "Iteration: 801, took 0.5123581886291504s- Accuracy=0.9816666666666667\n",
      "Iteration: 802, took 0.4997849464416504s- Accuracy=0.9816410256410256\n",
      "Iteration: 803, took 0.5295639038085938s- Accuracy=0.9816153846153847\n",
      "Iteration: 804, took 0.46958422660827637s- Accuracy=0.9816153846153847\n",
      "Iteration: 805, took 0.48221611976623535s- Accuracy=0.9815128205128205\n",
      "Iteration: 806, took 0.5027697086334229s- Accuracy=0.9815897435897436\n",
      "Iteration: 807, took 0.46738362312316895s- Accuracy=0.982025641025641\n",
      "Iteration: 808, took 0.45952773094177246s- Accuracy=0.9816923076923076\n",
      "Iteration: 809, took 0.46788954734802246s- Accuracy=0.9818717948717949\n",
      "Iteration: 810, took 0.49944233894348145s- Accuracy=0.9815128205128205\n",
      "Iteration: 811, took 0.5042688846588135s- Accuracy=0.9816666666666667\n",
      "Iteration: 812, took 0.4800455570220947s- Accuracy=0.981948717948718\n",
      "Iteration: 813, took 0.4870312213897705s- Accuracy=0.9816153846153847\n",
      "Iteration: 814, took 0.4995229244232178s- Accuracy=0.9818461538461538\n",
      "Iteration: 815, took 0.4707987308502197s- Accuracy=0.9816666666666667\n",
      "Iteration: 816, took 0.46708083152770996s- Accuracy=0.9815384615384616\n",
      "Iteration: 817, took 0.49263811111450195s- Accuracy=0.9817435897435898\n",
      "Iteration: 818, took 0.5226047039031982s- Accuracy=0.9818205128205129\n",
      "Iteration: 819, took 0.5586977005004883s- Accuracy=0.9817179487179487\n",
      "Iteration: 820, took 0.494525671005249s- Accuracy=0.9818974358974359\n",
      "Iteration: 821, took 0.47349977493286133s- Accuracy=0.981948717948718\n",
      "Iteration: 822, took 0.49849367141723633s- Accuracy=0.9813589743589743\n",
      "Iteration: 823, took 0.48215627670288086s- Accuracy=0.9817435897435898\n",
      "Iteration: 824, took 0.5015852451324463s- Accuracy=0.9816153846153847\n",
      "Iteration: 825, took 0.4597351551055908s- Accuracy=0.9815641025641025\n",
      "Iteration: 826, took 0.4505586624145508s- Accuracy=0.9817948717948718\n",
      "Iteration: 827, took 0.545173168182373s- Accuracy=0.9816923076923076\n",
      "Iteration: 828, took 0.5156924724578857s- Accuracy=0.9816410256410256\n",
      "Iteration: 829, took 0.4617292881011963s- Accuracy=0.9818974358974359\n",
      "Iteration: 830, took 0.5005548000335693s- Accuracy=0.9816666666666667\n",
      "Iteration: 831, took 0.5044150352478027s- Accuracy=0.9817179487179487\n",
      "Iteration: 832, took 0.47548770904541016s- Accuracy=0.982\n",
      "Iteration: 833, took 0.551750898361206s- Accuracy=0.9816666666666667\n",
      "Iteration: 834, took 0.4377579689025879s- Accuracy=0.9818717948717949\n",
      "Iteration: 835, took 0.4992096424102783s- Accuracy=0.9815897435897436\n",
      "Iteration: 836, took 0.47751545906066895s- Accuracy=0.9814358974358974\n",
      "Iteration: 837, took 0.6090116500854492s- Accuracy=0.9821025641025641\n",
      "Iteration: 838, took 0.6260898113250732s- Accuracy=0.9815384615384616\n",
      "Iteration: 839, took 0.521310567855835s- Accuracy=0.9817692307692307\n",
      "Iteration: 840, took 0.42798733711242676s- Accuracy=0.9816666666666667\n",
      "Iteration: 841, took 0.44440436363220215s- Accuracy=0.981948717948718\n",
      "Iteration: 842, took 0.49134182929992676s- Accuracy=0.982\n",
      "Iteration: 843, took 0.46337175369262695s- Accuracy=0.9815641025641025\n",
      "Iteration: 844, took 0.4638671875s- Accuracy=0.9820769230769231\n",
      "Iteration: 845, took 0.4573090076446533s- Accuracy=0.9818461538461538\n",
      "Iteration: 846, took 0.46380019187927246s- Accuracy=0.9816666666666667\n",
      "Iteration: 847, took 0.4781804084777832s- Accuracy=0.9817948717948718\n",
      "Iteration: 848, took 0.4833486080169678s- Accuracy=0.9817435897435898\n",
      "Iteration: 849, took 0.4936332702636719s- Accuracy=0.9816666666666667\n",
      "Iteration: 850, took 0.44989562034606934s- Accuracy=0.9818717948717949\n",
      "Iteration: 851, took 0.4996199607849121s- Accuracy=0.9816153846153847\n",
      "Iteration: 852, took 0.48249149322509766s- Accuracy=0.982\n",
      "Iteration: 853, took 0.4653611183166504s- Accuracy=0.9818461538461538\n",
      "Iteration: 854, took 0.4888014793395996s- Accuracy=0.9817692307692307\n",
      "Iteration: 855, took 0.5058767795562744s- Accuracy=0.9816923076923076\n",
      "Iteration: 856, took 0.4968681335449219s- Accuracy=0.9815384615384616\n",
      "Iteration: 857, took 0.4809608459472656s- Accuracy=0.9816153846153847\n",
      "Iteration: 858, took 0.4650099277496338s- Accuracy=0.9815897435897436\n",
      "Iteration: 859, took 0.4883909225463867s- Accuracy=0.9819230769230769\n",
      "Iteration: 860, took 0.5028002262115479s- Accuracy=0.9817179487179487\n",
      "Iteration: 861, took 0.4967153072357178s- Accuracy=0.9816923076923076\n",
      "Iteration: 862, took 0.476825475692749s- Accuracy=0.9822307692307692\n",
      "Iteration: 863, took 0.5219161510467529s- Accuracy=0.9818717948717949\n",
      "Iteration: 864, took 0.48627519607543945s- Accuracy=0.982\n",
      "Iteration: 865, took 0.5022284984588623s- Accuracy=0.9818717948717949\n",
      "Iteration: 866, took 0.4798238277435303s- Accuracy=0.9815641025641025\n",
      "Iteration: 867, took 0.5008895397186279s- Accuracy=0.9818205128205129\n",
      "Iteration: 868, took 0.49185776710510254s- Accuracy=0.982\n",
      "Iteration: 869, took 0.496462345123291s- Accuracy=0.9817948717948718\n",
      "Iteration: 870, took 0.49210596084594727s- Accuracy=0.9812820512820513\n",
      "Iteration: 871, took 0.4611396789550781s- Accuracy=0.982\n",
      "Iteration: 872, took 0.5506460666656494s- Accuracy=0.9818461538461538\n",
      "Iteration: 873, took 0.44893836975097656s- Accuracy=0.9819230769230769\n",
      "Iteration: 874, took 0.4177885055541992s- Accuracy=0.9815128205128205\n",
      "Iteration: 875, took 0.49811434745788574s- Accuracy=0.9817692307692307\n",
      "Iteration: 876, took 0.5361900329589844s- Accuracy=0.9815897435897436\n",
      "Iteration: 877, took 0.47924160957336426s- Accuracy=0.9814871794871795\n",
      "Iteration: 878, took 0.5392169952392578s- Accuracy=0.9818461538461538\n",
      "Iteration: 879, took 0.4956519603729248s- Accuracy=0.9816153846153847\n",
      "Iteration: 880, took 0.48044610023498535s- Accuracy=0.9814615384615385\n",
      "Iteration: 881, took 0.4995248317718506s- Accuracy=0.9817948717948718\n",
      "Iteration: 882, took 0.48981618881225586s- Accuracy=0.9814871794871795\n",
      "Iteration: 883, took 0.5163180828094482s- Accuracy=0.9818974358974359\n",
      "Iteration: 884, took 0.45613551139831543s- Accuracy=0.9814871794871795\n",
      "Iteration: 885, took 0.5023770332336426s- Accuracy=0.9816666666666667\n",
      "Iteration: 886, took 0.589719295501709s- Accuracy=0.9821282051282051\n",
      "Iteration: 887, took 0.5447835922241211s- Accuracy=0.9816923076923076\n",
      "Iteration: 888, took 0.5319397449493408s- Accuracy=0.9817179487179487\n",
      "Iteration: 889, took 0.6128666400909424s- Accuracy=0.9816923076923076\n",
      "Iteration: 890, took 0.5043137073516846s- Accuracy=0.9815128205128205\n",
      "Iteration: 891, took 0.4447801113128662s- Accuracy=0.9816923076923076\n",
      "Iteration: 892, took 0.500119686126709s- Accuracy=0.9821794871794872\n",
      "Iteration: 893, took 0.4719240665435791s- Accuracy=0.9816153846153847\n",
      "Iteration: 894, took 0.4865586757659912s- Accuracy=0.9817435897435898\n",
      "Iteration: 895, took 0.48176097869873047s- Accuracy=0.9815897435897436\n",
      "Iteration: 896, took 0.4424893856048584s- Accuracy=0.9814871794871795\n",
      "Iteration: 897, took 0.4901702404022217s- Accuracy=0.9814871794871795\n",
      "Iteration: 898, took 0.47592687606811523s- Accuracy=0.9816666666666667\n",
      "Iteration: 899, took 0.4983093738555908s- Accuracy=0.9817692307692307\n",
      "Iteration: 900, took 0.49220895767211914s- Accuracy=0.9816410256410256\n",
      "Iteration: 901, took 0.6084773540496826s- Accuracy=0.9816153846153847\n",
      "Iteration: 902, took 0.5192294120788574s- Accuracy=0.9817179487179487\n",
      "Iteration: 903, took 0.47169995307922363s- Accuracy=0.9817435897435898\n",
      "Iteration: 904, took 0.46525120735168457s- Accuracy=0.9817692307692307\n",
      "Iteration: 905, took 0.616119384765625s- Accuracy=0.9817948717948718\n",
      "Iteration: 906, took 0.505030632019043s- Accuracy=0.9816410256410256\n",
      "Iteration: 907, took 0.5389795303344727s- Accuracy=0.9817948717948718\n",
      "Iteration: 908, took 0.48099803924560547s- Accuracy=0.9814358974358974\n",
      "Iteration: 909, took 0.4919285774230957s- Accuracy=0.9814358974358974\n",
      "Iteration: 910, took 0.5194823741912842s- Accuracy=0.9816666666666667\n",
      "Iteration: 911, took 0.5106337070465088s- Accuracy=0.9816153846153847\n",
      "Iteration: 912, took 0.5173671245574951s- Accuracy=0.9816923076923076\n",
      "Iteration: 913, took 0.5272927284240723s- Accuracy=0.9815897435897436\n",
      "Iteration: 914, took 0.5004587173461914s- Accuracy=0.9816923076923076\n",
      "Iteration: 915, took 0.5179851055145264s- Accuracy=0.9816666666666667\n",
      "Iteration: 916, took 0.47484612464904785s- Accuracy=0.9815128205128205\n",
      "Iteration: 917, took 0.4984309673309326s- Accuracy=0.9814358974358974\n",
      "Iteration: 918, took 0.4862823486328125s- Accuracy=0.9818974358974359\n",
      "Iteration: 919, took 0.5006265640258789s- Accuracy=0.9816153846153847\n",
      "Iteration: 920, took 0.4954097270965576s- Accuracy=0.9818717948717949\n",
      "Iteration: 921, took 0.47803235054016113s- Accuracy=0.9814871794871795\n",
      "Iteration: 922, took 0.508756160736084s- Accuracy=0.9819230769230769\n",
      "Iteration: 923, took 0.5668787956237793s- Accuracy=0.9816666666666667\n",
      "Iteration: 924, took 0.5028133392333984s- Accuracy=0.9816923076923076\n",
      "Iteration: 925, took 0.5809915065765381s- Accuracy=0.9818974358974359\n",
      "Iteration: 926, took 0.6075804233551025s- Accuracy=0.9811538461538462\n",
      "Iteration: 927, took 0.5378038883209229s- Accuracy=0.9820769230769231\n",
      "Iteration: 928, took 0.48763537406921387s- Accuracy=0.9816666666666667\n",
      "Iteration: 929, took 0.5988659858703613s- Accuracy=0.9816410256410256\n",
      "Iteration: 930, took 0.4948863983154297s- Accuracy=0.981948717948718\n",
      "Iteration: 931, took 0.47481799125671387s- Accuracy=0.9815897435897436\n",
      "Iteration: 932, took 0.47347354888916016s- Accuracy=0.9815128205128205\n",
      "Iteration: 933, took 0.5167191028594971s- Accuracy=0.9818461538461538\n",
      "Iteration: 934, took 0.5046191215515137s- Accuracy=0.9817692307692307\n",
      "Iteration: 935, took 0.4674687385559082s- Accuracy=0.9818717948717949\n",
      "Iteration: 936, took 0.44788432121276855s- Accuracy=0.9818205128205129\n",
      "Iteration: 937, took 0.5065650939941406s- Accuracy=0.9815384615384616\n",
      "Iteration: 938, took 0.494854211807251s- Accuracy=0.9813846153846154\n",
      "Iteration: 939, took 0.47782254219055176s- Accuracy=0.982025641025641\n",
      "Iteration: 940, took 0.47177672386169434s- Accuracy=0.9816666666666667\n",
      "Iteration: 941, took 0.4832186698913574s- Accuracy=0.9812564102564103\n",
      "Iteration: 942, took 0.4839155673980713s- Accuracy=0.9816153846153847\n",
      "Iteration: 943, took 0.5009446144104004s- Accuracy=0.9816410256410256\n",
      "Iteration: 944, took 0.46344757080078125s- Accuracy=0.9816666666666667\n",
      "Iteration: 945, took 0.44036364555358887s- Accuracy=0.9815641025641025\n",
      "Iteration: 946, took 0.48363661766052246s- Accuracy=0.982025641025641\n",
      "Iteration: 947, took 0.5080766677856445s- Accuracy=0.9817692307692307\n",
      "Iteration: 948, took 0.5257585048675537s- Accuracy=0.9818461538461538\n",
      "Iteration: 949, took 0.46201014518737793s- Accuracy=0.9818205128205129\n",
      "Iteration: 950, took 0.5032260417938232s- Accuracy=0.981948717948718\n",
      "Iteration: 951, took 0.45466113090515137s- Accuracy=0.9817692307692307\n",
      "Iteration: 952, took 0.4719405174255371s- Accuracy=0.9815641025641025\n",
      "Iteration: 953, took 0.5067002773284912s- Accuracy=0.9814871794871795\n",
      "Iteration: 954, took 0.4568214416503906s- Accuracy=0.9819230769230769\n",
      "Iteration: 955, took 0.501164436340332s- Accuracy=0.9817692307692307\n",
      "Iteration: 956, took 0.40746021270751953s- Accuracy=0.981974358974359\n",
      "Iteration: 957, took 0.43109941482543945s- Accuracy=0.9816666666666667\n",
      "Iteration: 958, took 0.4845407009124756s- Accuracy=0.9819230769230769\n",
      "Iteration: 959, took 0.4777839183807373s- Accuracy=0.9818205128205129\n",
      "Iteration: 960, took 0.4452683925628662s- Accuracy=0.982051282051282\n",
      "Iteration: 961, took 0.51839280128479s- Accuracy=0.9817692307692307\n",
      "Iteration: 962, took 0.4839005470275879s- Accuracy=0.9814871794871795\n",
      "Iteration: 963, took 0.47669053077697754s- Accuracy=0.9818461538461538\n",
      "Iteration: 964, took 0.4822959899902344s- Accuracy=0.9815128205128205\n",
      "Iteration: 965, took 0.5190670490264893s- Accuracy=0.9819230769230769\n",
      "Iteration: 966, took 0.5430324077606201s- Accuracy=0.9815641025641025\n",
      "Iteration: 967, took 0.5153563022613525s- Accuracy=0.9816410256410256\n",
      "Iteration: 968, took 0.5469985008239746s- Accuracy=0.9815128205128205\n",
      "Iteration: 969, took 0.5369412899017334s- Accuracy=0.9821025641025641\n",
      "Iteration: 970, took 0.5100784301757812s- Accuracy=0.9814871794871795\n",
      "Iteration: 971, took 0.4799478054046631s- Accuracy=0.9816410256410256\n",
      "Iteration: 972, took 0.47727513313293457s- Accuracy=0.9820769230769231\n",
      "Iteration: 973, took 0.46147608757019043s- Accuracy=0.9817435897435898\n",
      "Iteration: 974, took 0.45282745361328125s- Accuracy=0.9815128205128205\n",
      "Iteration: 975, took 0.47103333473205566s- Accuracy=0.982\n",
      "Iteration: 976, took 0.47448205947875977s- Accuracy=0.9817435897435898\n",
      "Iteration: 977, took 0.45810508728027344s- Accuracy=0.9820769230769231\n",
      "Iteration: 978, took 0.4887816905975342s- Accuracy=0.9817692307692307\n",
      "Iteration: 979, took 0.512108325958252s- Accuracy=0.9816923076923076\n",
      "Iteration: 980, took 0.46663713455200195s- Accuracy=0.982025641025641\n",
      "Iteration: 981, took 0.4878396987915039s- Accuracy=0.9817692307692307\n",
      "Iteration: 982, took 0.4859631061553955s- Accuracy=0.9821282051282051\n",
      "Iteration: 983, took 0.45438480377197266s- Accuracy=0.981948717948718\n",
      "Iteration: 984, took 0.4714956283569336s- Accuracy=0.9816410256410256\n",
      "Iteration: 985, took 0.4943728446960449s- Accuracy=0.981948717948718\n",
      "Iteration: 986, took 0.4908461570739746s- Accuracy=0.9818461538461538\n",
      "Iteration: 987, took 0.47315335273742676s- Accuracy=0.9818974358974359\n",
      "Iteration: 988, took 0.4586799144744873s- Accuracy=0.981974358974359\n",
      "Iteration: 989, took 0.49751853942871094s- Accuracy=0.9818974358974359\n",
      "Iteration: 990, took 0.5006821155548096s- Accuracy=0.9817948717948718\n",
      "Iteration: 991, took 0.5295205116271973s- Accuracy=0.9821025641025641\n",
      "Iteration: 992, took 0.4617342948913574s- Accuracy=0.9817179487179487\n",
      "Iteration: 993, took 0.4566798210144043s- Accuracy=0.9815641025641025\n",
      "Iteration: 994, took 0.5734779834747314s- Accuracy=0.9818461538461538\n",
      "Iteration: 995, took 0.5318655967712402s- Accuracy=0.982\n",
      "Iteration: 996, took 0.5823285579681396s- Accuracy=0.9817692307692307\n",
      "Iteration: 997, took 0.4842042922973633s- Accuracy=0.9820769230769231\n",
      "Iteration: 998, took 0.4790809154510498s- Accuracy=0.9816923076923076\n",
      "Iteration: 999, took 0.44003963470458984s- Accuracy=0.9816666666666667\n",
      "Iteration: 1000, took 0.579552412033081s- Accuracy=0.9817948717948718\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3 = gradient_descent(X_train, Y_train, 1001, 0.1, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05d3aecc-6545-4f3b-aa3b-d3216fb67756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9543333333333334)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_predictions = make_prediction(W1, b1, W2, b2, W3, b3, X_cv)\n",
    "\n",
    "accuracy(cv_predictions, Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed9b65bf-c42c-4e72-9d85-99cc9b177935",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'details':{\n",
    "        'learning_rate':0.1,\n",
    "        'lambda': 0.05,\n",
    "        'batch_size': 64,\n",
    "        'epoch':1001\n",
    "    },\n",
    "    'W1':W1.tolist(),\n",
    "    'b1':b1.tolist(),\n",
    "    'W2':W2.tolist(),\n",
    "    'b2':b2.tolist(),\n",
    "    'W3':W3.tolist(),\n",
    "    'b3':b3.tolist()\n",
    "}\n",
    "import json\n",
    "with open('./weights_v2.1.json', 'w+') as f:\n",
    "    json.dump(weights, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12b80cd5-6804-4547-922e-26634d42c887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      2\n",
       "1      0\n",
       "2      9\n",
       "3      4\n",
       "4      3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_data = pd.read_csv('./dataset/test.csv')\n",
    "test_data = np.array(test_data)\n",
    "test_data = test_data.T / 255\n",
    "predictions = make_prediction(W1, b1, W2, b2, W3, b3, test_data)\n",
    "predictions = pd.DataFrame({'label':predictions.reshape((-1))})\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aef1662c-c339-433b-b017-a77f460fb591",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"kaggle_submission_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b8f30-5266-4f87-95ea-7b369f0376ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
